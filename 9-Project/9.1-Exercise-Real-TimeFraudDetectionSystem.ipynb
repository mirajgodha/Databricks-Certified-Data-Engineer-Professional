{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ddc2a42-5484-4766-9051-c7cac551fa7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸš¦ Real-Time Fraud Detection System â€“ Exercise Notebook\n",
    "\n",
    "## **Notebook Overview**\n",
    "\n",
    "***\n",
    "\n",
    "- Generate synthetic transaction data in Databricks using Python\n",
    "- Ingest streaming data with Databricks Structured Streaming\n",
    "- Apply ETL: cleansing, enrichment, deduplication, anomaly tagging\n",
    "- Implement rule-based fraud detection logic (NOT machine learning)\n",
    "- Store data through Bronze â†’ Silver â†’ Gold tables\n",
    "- Add checkpointing, monitoring, and fault tolerance\n",
    "\n",
    "***\n",
    "\n",
    "## 1. Setup \\& Initialization\n",
    "\n",
    "```python\n",
    "# Import needed libraries\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define workspace paths & table names\n",
    "bronze_path = \"dbfs:/mnt/fraud/bronze\"\n",
    "silver_path = \"dbfs:/mnt/fraud/silver\"\n",
    "gold_path = \"dbfs:/mnt/fraud/gold\"\n",
    "checkpoint_path = \"dbfs:/mnt/fraud/checkpoints\"\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 2. Synthetic Data Generation (Python â€“ Databricks Notebook Cell)\n",
    "\n",
    "```python\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_transaction():\n",
    "    return {\n",
    "        \"transaction_id\": f\"TX{random.randint(1000000,9999999)}\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"customer_id\": f\"C{random.randint(1000,9999)}\",\n",
    "        \"amount\": round(random.uniform(5,10000),2),\n",
    "        \"merchant_id\": f\"M{random.randint(10,999)}\",\n",
    "        \"country\": random.choice([\"IN\", \"US\", \"UK\", \"CA\", \"DE\", \"JP\", \"BR\"]),\n",
    "        \"channel\": random.choice([\"ecommerce\", \"offline\", \"mobile\"]),\n",
    "        \"payment_method\": random.choice([\"credit_card\", \"debit_card\", \"upi\", \"wallet\"]),\n",
    "        \"is_international\": random.choice([True, False])\n",
    "    }\n",
    "\n",
    "# Generate test data\n",
    "transactions = [generate_transaction() for _ in range(1000)]\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "transaction_schema = StructType([\n",
    "    StructField(\"transaction_id\", StringType()),\n",
    "    StructField(\"timestamp\", StringType()),\n",
    "    StructField(\"customer_id\", StringType()),\n",
    "    StructField(\"amount\", DoubleType()),\n",
    "    StructField(\"merchant_id\", StringType()),\n",
    "    StructField(\"country\", StringType()),\n",
    "    StructField(\"channel\", StringType()),\n",
    "    StructField(\"payment_method\", StringType()),\n",
    "    StructField(\"is_international\", BooleanType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(transactions, schema=transaction_schema)\n",
    "\n",
    "# Write as a single batch to a folder emulating streaming source\n",
    "df.write.mode(\"overwrite\").json(bronze_path + \"/raw\")\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 3. Real-Time Ingestion â€“ Structured Streaming\n",
    "\n",
    "```python\n",
    "# Read from simulated real-time source (bronze/raw)\n",
    "stream_df = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", checkpoint_path + \"/schema\")\n",
    "    .load(bronze_path + \"/raw\"))\n",
    "\n",
    "# Store raw events to Bronze table (append)\n",
    "bronze_query = (stream_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path + \"/bronze\")\n",
    "    .outputMode(\"append\")\n",
    "    .table(\"fraud_bronze\"))\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 4. ETL â€“ Cleansing, Enrichment, Deduplication\n",
    "\n",
    "```python\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "bronze_stream = spark.readStream.table(\"fraud_bronze\")\n",
    "\n",
    "# Cleansing: filter out incomplete rows\n",
    "clean_df = bronze_stream.filter(\n",
    "    \"transaction_id IS NOT NULL and customer_id IS NOT NULL and amount > 0\"\n",
    ")\n",
    "\n",
    "# Deduplication\n",
    "dedup_df = clean_df.withWatermark(\"timestamp\", \"10 seconds\").dropDuplicates([\"transaction_id\"])\n",
    "\n",
    "# Enrichment: flag high-value and international transactions\n",
    "enriched_df = (dedup_df\n",
    "    .withColumn(\"high_value\", F.col(\"amount\") > 5000)\n",
    "    .withColumn(\"is_night\", F.hour(F.to_timestamp(\"timestamp\")) >= 22)\n",
    ")\n",
    "\n",
    "# Write to Silver table\n",
    "silver_query = (enriched_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path + \"/silver\")\n",
    "    .outputMode(\"append\")\n",
    "    .table(\"fraud_silver\"))\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 5. Rule-Based Fraud Detection Logic (No ML)\n",
    "\n",
    "```python\n",
    "silver_stream = spark.readStream.table(\"fraud_silver\")\n",
    "\n",
    "# Add fraud rules column (simple, production-style logic)\n",
    "fraud_rules_df = (silver_stream\n",
    "    .withColumn(\"fraud_suspect\", \n",
    "       (\n",
    "           (F.col(\"is_international\") & F.col(\"high_value\")) |          # high-value & international\n",
    "           (F.col(\"channel\") == \"ecommerce\") & (F.col(\"amount\") > 8000) | # big ecommerce transactions\n",
    "           (F.col(\"is_night\") & (F.col(\"amount\") > 2000))                # night time, high amount\n",
    "       )\n",
    "    )\n",
    "    .withColumn(\"fraud_reason\",\n",
    "       F.when((F.col(\"is_international\") & F.col(\"high_value\")), \"International High Value\")\n",
    "        .when((F.col(\"channel\") == \"ecommerce\") & (F.col(\"amount\") > 8000), \"Ecommerce Large Payment\")\n",
    "        .when((F.col(\"is_night\") & (F.col(\"amount\") > 2000)), \"Night-Time Large Transaction\")\n",
    "        .otherwise(None)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write to Gold table\n",
    "gold_query = (fraud_rules_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path + \"/gold\")\n",
    "    .outputMode(\"append\")\n",
    "    .table(\"fraud_gold\"))\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 6. Monitoring, Checkpointing, and Fault Tolerance\n",
    "\n",
    "**Monitoring Metrics**\n",
    "\n",
    "```python\n",
    "# Example: Monitor counts and suspects\n",
    "fraud_gold_df = spark.read.table(\"fraud_gold\")\n",
    "fraud_gold_df.groupBy(\"fraud_suspect\", \"fraud_reason\").count().show()\n",
    "```\n",
    "\n",
    "**View latest suspect transactions**\n",
    "\n",
    "```python\n",
    "# Query recent fraud suspects\n",
    "spark.sql(\"SELECT * FROM fraud_gold WHERE fraud_suspect = true ORDER BY timestamp DESC LIMIT 10\").show()\n",
    "```\n",
    "\n",
    "**Check Streaming Query Health**\n",
    "\n",
    "```python\n",
    "# Access query progress and checkpoint status\n",
    "print(gold_query.recentProgress)\n",
    "```\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 7. Production Recap \\& Extension Ideas\n",
    "\n",
    "- All source, ETL, and output tables are **Delta** for reliability, ACID, and time travel\n",
    "- Checkpointing ensures fault tolerance \\& restarts\n",
    "- Extend with data lineage tags, periodic access audits, or integrate alerting (simple print/logging for now)\n",
    "\n",
    "***\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9.1-Exercise-Real-TimeFraudDetectionSystem",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
