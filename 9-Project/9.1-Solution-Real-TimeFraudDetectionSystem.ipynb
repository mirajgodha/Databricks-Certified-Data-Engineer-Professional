{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e850a654-8e67-45c9-a265-666473b3c185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table fraud_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de391789-e76d-408d-8bfd-611067965a55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(\"dbfs:/mnt/fraud/\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "793443fb-10c5-4e72-8008-92f59af02741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define workspace paths & table names\n",
    "bronze_path = \"dbfs:/mnt/fraud/bronze\"\n",
    "silver_path = \"dbfs:/mnt/fraud/silver\"\n",
    "gold_path = \"dbfs:/mnt/fraud/gold\"\n",
    "checkpoint_path = \"dbfs:/mnt/fraud/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d345c95-f58d-4e08-aa86-255f3553e777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def generate_transaction():\n",
    "    return {\n",
    "        \"transaction_id\": f\"TX{random.randint(1000000,9999999)}\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"customer_id\": f\"C{random.randint(1000,9999)}\",\n",
    "        \"amount\": round(random.uniform(5,10000),2),\n",
    "        \"merchant_id\": f\"M{random.randint(10,999)}\",\n",
    "        \"country\": random.choice([\"IN\", \"US\", \"UK\", \"CA\", \"DE\", \"JP\", \"BR\"]),\n",
    "        \"channel\": random.choice([\"ecommerce\", \"offline\", \"mobile\"]),\n",
    "        \"payment_method\": random.choice([\"credit_card\", \"debit_card\", \"upi\", \"wallet\"]),\n",
    "        \"is_international\": random.choice([True, False])\n",
    "    }\n",
    "\n",
    "# Generate test data\n",
    "transactions = [dict(**{k: v for k, v in t.items() if k != 'timestamp'}, timestamp=datetime.fromisoformat(t['timestamp'])) for t in [generate_transaction() for _ in range(1000)]]\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "transaction_schema = StructType([\n",
    "    StructField(\"transaction_id\", StringType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"customer_id\", StringType()),\n",
    "    StructField(\"amount\", DoubleType()),\n",
    "    StructField(\"merchant_id\", StringType()),\n",
    "    StructField(\"country\", StringType()),\n",
    "    StructField(\"channel\", StringType()),\n",
    "    StructField(\"payment_method\", StringType()),\n",
    "    StructField(\"is_international\", BooleanType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(transactions, schema=transaction_schema)\n",
    "\n",
    "df = df.withColumn(\"timestamp\", F.to_timestamp(\"timestamp\"))  \n",
    "print(df.schema)\n",
    "\n",
    "# Write as a single batch to a folder emulating streaming source\n",
    "df.write.mode(\"overwrite\").parquet(bronze_path + \"/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7dcd94-ca3f-4cfc-b975-9325e0bda5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from simulated real-time source (bronze/raw)\n",
    "stream_df = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"parquet\")\n",
    "    .option(\"cloudFiles.schemaLocation\", checkpoint_path + \"/schema\")\n",
    "    .load(bronze_path + \"/raw\"))\n",
    "\n",
    "# Store raw events to Bronze table (append)\n",
    "bronze_query = (stream_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path + \"/bronze\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(availableNow=True)\n",
    "    .table(\"fraud_bronze\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce8c05e-a0f6-4077-9f82-3452a0381836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe table fraud_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5dba3b4-db1e-46a9-9d58-65c9382403b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bronze_stream = spark.readStream.table(\"fraud_bronze\")\n",
    "\n",
    "# Cleansing: filter out incomplete rows\n",
    "clean_df = bronze_stream.filter(\n",
    "    \"transaction_id IS NOT NULL and customer_id IS NOT NULL and amount > 0\"\n",
    ")\n",
    "\n",
    "# Deduplication\n",
    "dedup_df = clean_df.withWatermark(\"timestamp\", \"10 seconds\").dropDuplicates([\"transaction_id\"])\n",
    "\n",
    "# Enrichment: flag high-value and international transactions\n",
    "enriched_df = (dedup_df\n",
    "    .withColumn(\"high_value\", F.col(\"amount\") > 5000)\n",
    "    .withColumn(\"is_night\", F.hour(F.to_timestamp(\"timestamp\")) >= 22)\n",
    ")\n",
    "\n",
    "# Write to Silver table\n",
    "silver_query = (enriched_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path + \"/silver\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(availableNow=True)\n",
    "    .table(\"fraud_silver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c42e4a38-af7c-4613-b55c-87836f215c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_stream = spark.readStream.table(\"fraud_silver\")\n",
    "\n",
    "# Add fraud rules column (simple, production-style logic)\n",
    "fraud_rules_df = (silver_stream\n",
    "    .withColumn(\"fraud_suspect\", \n",
    "       (\n",
    "           (F.col(\"is_international\") & F.col(\"high_value\")) |          # high-value & international\n",
    "           (F.col(\"channel\") == \"ecommerce\") & (F.col(\"amount\") > 8000) | # big ecommerce transactions\n",
    "           (F.col(\"is_night\") & (F.col(\"amount\") > 2000))                # night time, high amount\n",
    "       )\n",
    "    )\n",
    "    .withColumn(\"fraud_reason\",\n",
    "       F.when((F.col(\"is_international\") & F.col(\"high_value\")), \"International High Value\")\n",
    "        .when((F.col(\"channel\") == \"ecommerce\") & (F.col(\"amount\") > 8000), \"Ecommerce Large Payment\")\n",
    "        .when((F.col(\"is_night\") & (F.col(\"amount\") > 2000)), \"Night-Time Large Transaction\")\n",
    "        .otherwise(None)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write to Gold table\n",
    "gold_query = (fraud_rules_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path + \"/gold\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(availableNow=True)\n",
    "    .table(\"fraud_gold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10bbd1a1-5c1c-4efd-b60b-ec4bc1dae9c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Monitor counts and suspects\n",
    "fraud_gold_df = spark.read.table(\"fraud_gold\")\n",
    "fraud_gold_df.groupBy(\"fraud_suspect\", \"fraud_reason\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7f619b3-460f-47ca-829d-f63cc173d89f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- View latest suspect transactions\n",
    "\n",
    "-- Query recent fraud suspects\n",
    "SELECT customer_id,channel, payment_method,fraud_reason FROM fraud_gold WHERE fraud_suspect = true ORDER BY timestamp DESC LIMIT 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc983835-4c57-4881-953c-d2a4f253a2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Check Streaming Query Health\n",
    "\n",
    "# Access query progress and checkpoint status\n",
    "print(gold_query.recentProgress)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8198389616906499,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "9.1-Solution-Real-TimeFraudDetectionSystem",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
