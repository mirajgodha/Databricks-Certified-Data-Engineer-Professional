{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d8bfeb1-526f-408e-a151-bda8ab8ff997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unity Catalog and Table Management Lab - Solution Guide\n",
    "\n",
    "## Overview\n",
    "This solution guide provides comprehensive answers and explanations for all exercises in the Unity Catalog and Table Management lab. Each solution includes detailed explanations and best practices.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 1 Solutions: Unity Catalog Setup and Managed vs External Tables\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: Where is the data for the managed table stored?**\n",
    "\n",
    "**Answer:**\n",
    "Managed tables in Unity Catalog store their data in **Unity Catalog managed storage locations**:\n",
    "- **AWS**: `s3://unity-catalog-storage/metastore-id/tables/catalog.schema.table/`\n",
    "- **Azure**: `abfss://container@storage.dfs.core.windows.net/metastore-id/tables/catalog.schema.table/`\n",
    "- **GCP**: `gs://unity-catalog-storage/metastore-id/tables/catalog.schema.table/`\n",
    "\n",
    "The exact location is managed automatically by Unity Catalog and can be viewed using:\n",
    "```sql\n",
    "DESCRIBE DETAIL hr_analytics_lab.hr_data.employees_managed;\n",
    "-- Look for the 'location' field in the output\n",
    "```\n",
    "\n",
    "**Storage characteristics:**\n",
    "- **Fully managed** by Databricks Unity Catalog\n",
    "- **Automatic organization** by catalog/schema/table hierarchy\n",
    "- **No user configuration** of storage paths required\n",
    "- **Integrated backup** and versioning through Unity Catalog\n",
    "\n",
    "**Q2: What are the benefits of using managed tables?**\n",
    "\n",
    "**Answer:**\n",
    "Key benefits of managed tables:\n",
    "\n",
    "1. **Simplified Management:**\n",
    "   - No need to manage storage paths manually\n",
    "   - Automatic file organization and cleanup\n",
    "   - Built-in metadata management\n",
    "\n",
    "2. **Enhanced Security:**\n",
    "   - Centralized access control through Unity Catalog\n",
    "   - Automatic encryption in transit and at rest\n",
    "   - No direct cloud storage permissions required\n",
    "\n",
    "3. **Data Governance:**\n",
    "   - Automatic lineage tracking\n",
    "   - Built-in audit logging\n",
    "   - Centralized metadata and tagging\n",
    "\n",
    "4. **Performance Optimization:**\n",
    "   - Optimized storage layout\n",
    "   - Automatic compaction and optimization\n",
    "   - Better query performance through Unity Catalog optimizations\n",
    "\n",
    "5. **Backup & Recovery:**\n",
    "   - Automatic backup integration\n",
    "   - Point-in-time recovery capabilities\n",
    "   - Disaster recovery built-in\n",
    "\n",
    "**Q3: Who owns the lifecycle of managed table data?**\n",
    "\n",
    "**Answer:**\n",
    "**Unity Catalog owns the complete lifecycle** of managed table data:\n",
    "\n",
    "**Creation Phase:**\n",
    "- Unity Catalog creates storage directories\n",
    "- Manages initial table structure and metadata\n",
    "- Establishes security and access controls\n",
    "\n",
    "**Operational Phase:**\n",
    "- Handles data file organization and compaction\n",
    "- Manages metadata updates and schema evolution  \n",
    "- Controls access permissions and audit logging\n",
    "\n",
    "**Maintenance Phase:**\n",
    "- Automatic cleanup of old files (via VACUUM)\n",
    "- Optimization and performance tuning\n",
    "- Backup and replication management\n",
    "\n",
    "**Deletion Phase:**\n",
    "- When table is dropped, Unity Catalog removes ALL data\n",
    "- Complete cleanup of storage and metadata\n",
    "- No orphaned files left behind\n",
    "\n",
    "**User Responsibilities:**\n",
    "- Data insertion and business logic\n",
    "- Query performance optimization \n",
    "- Schema design and constraint definition\n",
    "- Access control configuration\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 2 Solutions: External Locations and Storage Credentials\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: What are the main benefits of external locations in Unity Catalog?**\n",
    "\n",
    "**Answer:**\n",
    "External locations provide several critical advantages:\n",
    "\n",
    "1. **Data Sovereignty:**\n",
    "   ```sql\n",
    "   -- Data remains in your controlled cloud storage\n",
    "   CREATE EXTERNAL LOCATION my_data_lake\n",
    "   URL 's3://my-company-datalake/sensitive-data/'\n",
    "   CREDENTIAL my_aws_credential;\n",
    "   ```\n",
    "   - **Ownership**: You maintain full ownership of data\n",
    "   - **Control**: Complete control over storage policies\n",
    "   - **Compliance**: Meet regulatory requirements for data residency\n",
    "\n",
    "2. **Integration with Existing Systems:**\n",
    "   ```sql\n",
    "   -- Connect to existing data lakes\n",
    "   CREATE TABLE analytics.sales_external\n",
    "   USING DELTA\n",
    "   LOCATION 's3://existing-datalake/sales/'\n",
    "   ```\n",
    "   - **Legacy Integration**: Connect existing data lakes to Unity Catalog\n",
    "   - **Multi-tool Access**: Same data accessible from multiple analytics tools\n",
    "   - **Gradual Migration**: Migrate to Unity Catalog without data movement\n",
    "\n",
    "3. **Advanced Security:**\n",
    "   ```sql\n",
    "   CREATE STORAGE CREDENTIAL secure_credential\n",
    "   TYPE IAM\n",
    "   IAM_ROLE 'arn:aws:iam::account:role/databricks-restricted-role'\n",
    "   ```\n",
    "   - **Fine-grained Access**: Credential-based access control\n",
    "   - **Network Security**: VPC endpoints and network isolation\n",
    "   - **Audit Trails**: Complete access logging\n",
    "\n",
    "4. **Cost Management:**\n",
    "   - **Storage Flexibility**: Use different storage classes (hot, cold, archive)\n",
    "   - **Lifecycle Policies**: Automatic data archiving\n",
    "   - **Multi-region**: Optimize for regional access patterns\n",
    "\n",
    "5. **Disaster Recovery:**\n",
    "   - **Geographic Distribution**: Data in multiple regions\n",
    "   - **Backup Strategies**: Independent backup systems\n",
    "   - **Business Continuity**: Data survives platform changes\n",
    "\n",
    "**Q2: When would you choose external tables over managed tables?**\n",
    "\n",
    "**Answer:**\n",
    "Choose external tables when:\n",
    "\n",
    "**Regulatory & Compliance Scenarios:**\n",
    "```sql\n",
    "-- Financial data that must remain in specific regions\n",
    "CREATE TABLE finance.transactions_external\n",
    "LOCATION 's3://financial-data-eu-west-1/transactions/'\n",
    "```\n",
    "- **Data residency** requirements (GDPR, financial regulations)\n",
    "- **Audit requirements** for data location control\n",
    "- **Compliance** with industry standards\n",
    "\n",
    "**Legacy Integration:**\n",
    "```sql\n",
    "-- Existing data lake with multiple consumers\n",
    "CREATE TABLE marketing.customer_data_external  \n",
    "LOCATION 's3://existing-customer-lake/profiles/'\n",
    "```\n",
    "- **Existing data lakes** with established processes\n",
    "- **Multi-platform access** (Spark, Snowflake, etc.)\n",
    "- **Gradual migration** strategies\n",
    "\n",
    "**Advanced Architecture Patterns:**\n",
    "```sql\n",
    "-- Data mesh pattern with domain ownership\n",
    "CREATE TABLE sales.regional_sales_external\n",
    "LOCATION 's3://sales-domain-storage/regional/'\n",
    "```\n",
    "- **Data mesh** architectures\n",
    "- **Domain-driven** data ownership\n",
    "- **Federated** data management\n",
    "\n",
    "**Performance & Scale:**\n",
    "- **Very large datasets** (petabyte scale)\n",
    "- **Specific storage optimizations** required\n",
    "- **Custom partitioning** strategies\n",
    "\n",
    "**Use managed tables when:**\n",
    "- **Simple analytics** use cases\n",
    "- **Standard compliance** requirements sufficient\n",
    "- **Want simplified management**\n",
    "- **Team lacks cloud storage expertise**\n",
    "\n",
    "**Q3: What security advantages do storage credentials provide?**\n",
    "\n",
    "**Answer:**\n",
    "Storage credentials provide multi-layered security:\n",
    "\n",
    "1. **Identity-Based Access Control:**\n",
    "   ```sql\n",
    "   CREATE STORAGE CREDENTIAL analytics_team_credential\n",
    "   TYPE IAM\n",
    "   IAM_ROLE 'arn:aws:iam::123456789:role/analytics-team-role'\n",
    "   COMMENT 'Restricted access for analytics team'\n",
    "   ```\n",
    "   - **IAM Integration**: Leverages cloud provider IAM systems\n",
    "   - **Principle of Least Privilege**: Minimal required permissions\n",
    "   - **Role-Based Access**: Team and function-specific credentials\n",
    "\n",
    "2. **Centralized Credential Management:**\n",
    "   ```sql\n",
    "   -- Centralized credential updates\n",
    "   ALTER STORAGE CREDENTIAL analytics_team_credential\n",
    "   SET IAM_ROLE 'arn:aws:iam::123456789:role/analytics-team-role-v2'\n",
    "   ```\n",
    "   - **Single Point of Control**: Update credentials centrally\n",
    "   - **Audit Trail**: Track all credential usage\n",
    "   - **Rotation Policies**: Regular credential rotation\n",
    "\n",
    "3. **Fine-Grained Access Control:**\n",
    "   ```sql\n",
    "   -- Grant specific access to external locations\n",
    "   GRANT CREATE TABLE ON EXTERNAL LOCATION secure_data_location \n",
    "   TO analytics_team\n",
    "   ```\n",
    "   - **Location-Level Permissions**: Control access per storage location\n",
    "   - **Operation-Level Control**: Read vs write vs admin permissions\n",
    "   - **Resource Isolation**: Separate credentials for different data tiers\n",
    "\n",
    "4. **Network Security:**\n",
    "   ```sql\n",
    "   CREATE EXTERNAL LOCATION vpc_only_data\n",
    "   URL 's3://private-vpc-bucket/sensitive/'\n",
    "   CREDENTIAL vpc_restricted_credential\n",
    "   ```\n",
    "   - **VPC Endpoints**: Private network connectivity\n",
    "   - **Network Policies**: Restrict network access\n",
    "   - **Encryption in Transit**: Secure data transfer\n",
    "\n",
    "5. **Monitoring & Compliance:**\n",
    "   - **Access Logging**: Complete audit trail of data access\n",
    "   - **Usage Monitoring**: Track credential usage patterns\n",
    "   - **Compliance Reporting**: Generate access reports for audits\n",
    "\n",
    "**Security Best Practices:**\n",
    "```sql\n",
    "-- Example comprehensive security setup\n",
    "CREATE STORAGE CREDENTIAL production_secure_credential\n",
    "TYPE IAM\n",
    "IAM_ROLE 'arn:aws:iam::prod:role/databricks-production-readonly'\n",
    "COMMENT 'Production data access with read-only permissions'\n",
    "\n",
    "CREATE EXTERNAL LOCATION production_data_lake\n",
    "URL 's3://prod-data-lake-encrypted/analytics/'\n",
    "CREDENTIAL production_secure_credential\n",
    "COMMENT 'Production data lake with encryption and VPC access'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 3 Solutions: Working with Different Types of Views\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: What is the difference between temporary and global temporary views?**\n",
    "\n",
    "**Answer:**\n",
    "Key differences between temporary and global temporary views:\n",
    "\n",
    "| Aspect | Temporary Views | Global Temporary Views |\n",
    "|--------|----------------|----------------------|\n",
    "| **Scope** | Current session only | Cross-session within cluster |\n",
    "| **Syntax** | `CREATE TEMPORARY VIEW` | `CREATE GLOBAL TEMPORARY VIEW` |\n",
    "| **Namespace** | Default namespace | `global_temp` database |\n",
    "| **Lifetime** | Until session ends | Until cluster terminates |\n",
    "| **Sharing** | Single user/session | Multiple sessions on same cluster |\n",
    "\n",
    "**Temporary Views:**\n",
    "```sql\n",
    "-- Only visible in current session\n",
    "CREATE TEMPORARY VIEW session_analytics AS\n",
    "SELECT department, AVG(salary) as avg_sal\n",
    "FROM employees WHERE is_active = true\n",
    "GROUP BY department;\n",
    "\n",
    "-- Query in same session: ✅ Works\n",
    "SELECT * FROM session_analytics;\n",
    "\n",
    "-- Query from different session: ❌ Fails - view not found\n",
    "```\n",
    "\n",
    "**Global Temporary Views:**\n",
    "```sql\n",
    "-- Visible across sessions on same cluster\n",
    "CREATE GLOBAL TEMPORARY VIEW global_temp.cluster_analytics AS\n",
    "SELECT department, COUNT(*) as emp_count\n",
    "FROM employees WHERE is_active = true\n",
    "GROUP BY department;\n",
    "\n",
    "-- Query from any session on cluster: ✅ Works\n",
    "SELECT * FROM global_temp.cluster_analytics;\n",
    "```\n",
    "\n",
    "**Use Cases:**\n",
    "- **Temporary Views**: Personal analysis, debugging, ad-hoc queries\n",
    "- **Global Temporary Views**: Cross-session collaboration, shared calculations\n",
    "\n",
    "**Q2: When would you use a stored view vs a temporary view?**\n",
    "\n",
    "**Answer:**\n",
    "Choose based on persistence, sharing, and governance needs:\n",
    "\n",
    "**Use Stored Views When:**\n",
    "\n",
    "1. **Business Logic Standardization:**\n",
    "   ```sql\n",
    "   CREATE VIEW finance.monthly_revenue AS\n",
    "   SELECT \n",
    "       YEAR(order_date) as year,\n",
    "       MONTH(order_date) as month,\n",
    "       SUM(amount) as total_revenue\n",
    "   FROM sales.orders\n",
    "   GROUP BY YEAR(order_date), MONTH(order_date)\n",
    "   ```\n",
    "   - **Reusable** across multiple queries and users\n",
    "   - **Consistent** business logic implementation\n",
    "   - **Centralized** definition management\n",
    "\n",
    "2. **Security & Access Control:**\n",
    "   ```sql\n",
    "   CREATE VIEW hr.employee_summary AS\n",
    "   SELECT employee_id, first_name, last_name, department\n",
    "   FROM hr.employees_full  -- Hide salary and PII\n",
    "   WHERE is_active = true\n",
    "   ```\n",
    "   - **Data masking** and column-level security\n",
    "   - **Row-level filtering** for different user groups\n",
    "   - **Governance** through Unity Catalog permissions\n",
    "\n",
    "3. **Performance Optimization:**\n",
    "   ```sql\n",
    "   CREATE VIEW analytics.customer_360 AS\n",
    "   SELECT c.*, o.total_orders, p.total_payments\n",
    "   FROM customers c\n",
    "   JOIN (SELECT customer_id, COUNT(*) as total_orders FROM orders GROUP BY customer_id) o\n",
    "   JOIN (SELECT customer_id, SUM(amount) as total_payments FROM payments GROUP BY customer_id) p\n",
    "   ```\n",
    "   - **Complex joins** abstracted into simple interface\n",
    "   - **Query optimization** by database engine\n",
    "   - **Consistent** performance patterns\n",
    "\n",
    "**Use Temporary Views When:**\n",
    "\n",
    "1. **Exploratory Data Analysis:**\n",
    "   ```sql\n",
    "   CREATE TEMPORARY VIEW temp_outliers AS\n",
    "   SELECT * FROM sales_data \n",
    "   WHERE amount > (SELECT PERCENTILE_APPROX(amount, 0.95) FROM sales_data)\n",
    "   ```\n",
    "   - **Ad-hoc analysis** and data exploration\n",
    "   - **Quick prototyping** of analytical queries\n",
    "   - **Personal workspace** without affecting others\n",
    "\n",
    "2. **ETL Pipeline Intermediate Steps:**\n",
    "   ```sql\n",
    "   -- Step 1: Clean data\n",
    "   CREATE TEMPORARY VIEW clean_data AS\n",
    "   SELECT * FROM raw_data WHERE quality_flag = 'valid'\n",
    "   \n",
    "   -- Step 2: Transform\n",
    "   CREATE TEMPORARY VIEW transformed_data AS  \n",
    "   SELECT id, UPPER(name), normalized_amount FROM clean_data\n",
    "   \n",
    "   -- Step 3: Load final table\n",
    "   INSERT INTO final_table SELECT * FROM transformed_data\n",
    "   ```\n",
    "   - **Pipeline isolation** from concurrent executions\n",
    "   - **Memory efficiency** (automatic cleanup)\n",
    "   - **No metadata pollution**\n",
    "\n",
    "3. **Session-Specific Configuration:**\n",
    "   ```sql\n",
    "   CREATE TEMPORARY VIEW current_user_data AS\n",
    "   SELECT * FROM all_user_data \n",
    "   WHERE user_id = '${current_user_id}'\n",
    "   ```\n",
    "   - **User-specific** data filtering\n",
    "   - **Dynamic** content based on session context\n",
    "   - **Privacy** (no persistent access logs)\n",
    "\n",
    "**Decision Matrix:**\n",
    "- **Permanent + Shared**: Stored View\n",
    "- **Permanent + Personal**: Consider materialized table instead\n",
    "- **Temporary + Shared**: Global Temporary View\n",
    "- **Temporary + Personal**: Temporary View\n",
    "\n",
    "**Q3: How do views contribute to data governance in Unity Catalog?**\n",
    "\n",
    "**Answer:**\n",
    "Views are critical governance tools in Unity Catalog:\n",
    "\n",
    "1. **Access Control Layer:**\n",
    "   ```sql\n",
    "   -- Create view that masks PII\n",
    "   CREATE VIEW hr.employees_public AS\n",
    "   SELECT \n",
    "       employee_id,\n",
    "       first_name,\n",
    "       last_name,\n",
    "       department,\n",
    "       CASE \n",
    "           WHEN current_user() IN ('hr_manager', 'ceo') THEN salary\n",
    "           ELSE NULL \n",
    "       END as salary\n",
    "   FROM hr.employees_full\n",
    "   \n",
    "   -- Grant access to view, not base table\n",
    "   GRANT SELECT ON VIEW hr.employees_public TO analysts\n",
    "   ```\n",
    "   - **Column-level security**: Hide sensitive columns\n",
    "   - **Row-level filtering**: Show only relevant records\n",
    "   - **Dynamic access**: User-based data access\n",
    "\n",
    "2. **Data Lineage and Audit:**\n",
    "   ```sql\n",
    "   CREATE VIEW analytics.quarterly_metrics AS\n",
    "   SELECT quarter, region, SUM(revenue) as total_revenue\n",
    "   FROM sales.fact_sales  -- Lineage tracked automatically\n",
    "   GROUP BY quarter, region\n",
    "   ```\n",
    "   - **Automatic lineage**: Unity Catalog tracks view dependencies\n",
    "   - **Impact analysis**: Understand downstream effects of changes\n",
    "   - **Audit trails**: Track view usage and access patterns\n",
    "\n",
    "3. **Data Quality Enforcement:**\n",
    "   ```sql\n",
    "   CREATE VIEW finance.validated_transactions AS\n",
    "   SELECT * FROM finance.all_transactions\n",
    "   WHERE amount > 0 \n",
    "     AND transaction_date >= '2020-01-01'\n",
    "     AND status IN ('completed', 'pending')\n",
    "   ```\n",
    "   - **Quality filters**: Ensure only valid data is accessible\n",
    "   - **Business rules**: Encode domain knowledge in views\n",
    "   - **Consistency**: Standardize data quality across consumers\n",
    "\n",
    "4. **Documentation and Metadata:**\n",
    "   ```sql\n",
    "   CREATE VIEW customer.customer_metrics\n",
    "   COMMENT 'Customer lifetime value and engagement metrics. Updated daily at 2 AM UTC.'\n",
    "   AS SELECT customer_id, clv, engagement_score FROM customer.analytics_base\n",
    "   \n",
    "   ALTER VIEW customer.customer_metrics \n",
    "   SET TBLPROPERTIES (\n",
    "     'owner' = 'customer_analytics_team',\n",
    "     'refresh_frequency' = 'daily',\n",
    "     'data_classification' = 'customer_pii'\n",
    "   )\n",
    "   ```\n",
    "   - **Self-documenting**: Comments explain business context\n",
    "   - **Metadata tags**: Classification and ownership information\n",
    "   - **Discovery**: Help users find and understand data\n",
    "\n",
    "5. **Change Management:**\n",
    "   ```sql\n",
    "   -- Version 1: Original view\n",
    "   CREATE VIEW sales.monthly_summary AS\n",
    "   SELECT month, SUM(amount) as total FROM sales.orders GROUP BY month\n",
    "   \n",
    "   -- Version 2: Enhanced view (backward compatible)\n",
    "   CREATE OR REPLACE VIEW sales.monthly_summary AS\n",
    "   SELECT \n",
    "       month, \n",
    "       SUM(amount) as total,\n",
    "       COUNT(*) as transaction_count,  -- New column\n",
    "       AVG(amount) as avg_amount       -- New column\n",
    "   FROM sales.orders GROUP BY month\n",
    "   ```\n",
    "   - **Schema evolution**: Add columns without breaking consumers\n",
    "   - **Backward compatibility**: Maintain existing interfaces\n",
    "   - **Centralized updates**: Change logic in one place\n",
    "\n",
    "**Governance Best Practices:**\n",
    "- **Naming conventions**: Use consistent, descriptive view names\n",
    "- **Documentation**: Always add meaningful comments\n",
    "- **Access patterns**: Grant least-privilege access\n",
    "- **Regular review**: Audit view usage and permissions\n",
    "- **Version control**: Track view definition changes\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 4 Solutions: CREATE TABLE AS SELECT (CTAS) Operations\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: How does CTAS differ from regular CREATE TABLE followed by INSERT?**\n",
    "\n",
    "**Answer:**\n",
    "CTAS and CREATE + INSERT have significant differences:\n",
    "\n",
    "**CREATE TABLE AS SELECT (CTAS):**\n",
    "```sql\n",
    "-- Single atomic operation\n",
    "CREATE TABLE analytics.high_performers AS\n",
    "SELECT employee_id, salary, department\n",
    "FROM hr.employees WHERE salary > 100000\n",
    "```\n",
    "\n",
    "**CREATE TABLE + INSERT:**\n",
    "```sql\n",
    "-- Two separate operations\n",
    "CREATE TABLE analytics.high_performers (\n",
    "    employee_id INT,\n",
    "    salary DOUBLE, \n",
    "    department STRING\n",
    ");\n",
    "\n",
    "INSERT INTO analytics.high_performers\n",
    "SELECT employee_id, salary, department  \n",
    "FROM hr.employees WHERE salary > 100000\n",
    "```\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "1. **Atomicity:**\n",
    "   - **CTAS**: Single atomic transaction - either complete success or complete failure\n",
    "   - **CREATE + INSERT**: Two transactions - table might exist empty if INSERT fails\n",
    "\n",
    "2. **Schema Management:**\n",
    "   - **CTAS**: Schema automatically inferred from SELECT query\n",
    "   - **CREATE + INSERT**: Schema must be explicitly defined and match INSERT data\n",
    "\n",
    "3. **Performance:**\n",
    "   - **CTAS**: Optimized single-pass operation, parallel execution\n",
    "   - **CREATE + INSERT**: Potential overhead from two operations, metadata updates\n",
    "\n",
    "4. **Metadata Handling:**\n",
    "   - **CTAS**: Column names, types, nullability inferred automatically\n",
    "   - **CREATE + INSERT**: Manual schema definition, potential type mismatches\n",
    "\n",
    "5. **Error Handling:**\n",
    "   ```sql\n",
    "   -- CTAS: If query fails, no table created\n",
    "   CREATE TABLE test AS SELECT bad_column FROM non_existent_table  -- Clean failure\n",
    "   \n",
    "   -- CREATE + INSERT: Table exists even if INSERT fails\n",
    "   CREATE TABLE test (id INT)        -- ✅ Succeeds\n",
    "   INSERT INTO test SELECT bad_col   -- ❌ Fails, but table still exists\n",
    "   ```\n",
    "\n",
    "**When to Use Each:**\n",
    "\n",
    "**Use CTAS when:**\n",
    "- Creating tables from analytical queries\n",
    "- Schema should match source data exactly\n",
    "- Want atomic operation guarantees\n",
    "- Prototyping and exploration\n",
    "\n",
    "**Use CREATE + INSERT when:**\n",
    "- Need explicit schema control\n",
    "- Adding constraints not supported in CTAS\n",
    "- Incremental loading patterns\n",
    "- Complex business logic requiring separation\n",
    "\n",
    "**Q2: What are the benefits of partitioning in the CTAS example?**\n",
    "\n",
    "**Answer:**\n",
    "The CTAS partitioning example demonstrates several key benefits:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE hr_analytics_lab.analytics.employees_by_location\n",
    "COMMENT \"Contains PII - Employee data partitioned by city and birth_year\"\n",
    "PARTITIONED BY (city, birth_year)\n",
    "AS\n",
    "SELECT \n",
    "    employee_id as id,\n",
    "    name,\n",
    "    email,\n",
    "    birth_date,\n",
    "    city,\n",
    "    YEAR(birth_date) as birth_year,\n",
    "    department,\n",
    "    salary\n",
    "FROM employees WHERE is_active = true\n",
    "```\n",
    "\n",
    "**Performance Benefits:**\n",
    "\n",
    "1. **Query Performance:**\n",
    "   ```sql\n",
    "   -- Partition elimination - only scans relevant partitions\n",
    "   SELECT COUNT(*) FROM employees_by_location \n",
    "   WHERE city = 'New York' AND birth_year = 1985\n",
    "   -- Only scans city=New York/birth_year=1985 partition\n",
    "   ```\n",
    "   - **Partition elimination**: Skip irrelevant data files\n",
    "   - **Parallel processing**: Each partition processed independently\n",
    "   - **Reduced I/O**: Read only necessary data\n",
    "\n",
    "2. **Data Organization:**\n",
    "   ```\n",
    "   /employees_by_location/\n",
    "   ├── city=New York/birth_year=1985/part-001.parquet\n",
    "   ├── city=New York/birth_year=1986/part-002.parquet  \n",
    "   ├── city=Chicago/birth_year=1985/part-003.parquet\n",
    "   └── city=Chicago/birth_year=1986/part-004.parquet\n",
    "   ```\n",
    "   - **Logical organization**: Data organized by business dimensions\n",
    "   - **File pruning**: Query engines skip entire directories\n",
    "   - **Metadata efficiency**: Partition metadata cached separately\n",
    "\n",
    "**Operational Benefits:**\n",
    "\n",
    "3. **Data Management:**\n",
    "   ```sql\n",
    "   -- Drop specific partitions efficiently\n",
    "   ALTER TABLE employees_by_location \n",
    "   DROP PARTITION (city = 'Chicago', birth_year = 1980)\n",
    "   \n",
    "   -- Add new partition\n",
    "   ALTER TABLE employees_by_location \n",
    "   ADD PARTITION (city = 'Austin', birth_year = 2000)\n",
    "   ```\n",
    "   - **Granular operations**: Manage subsets of data efficiently\n",
    "   - **Bulk operations**: Load/delete entire partitions quickly\n",
    "   - **Maintenance**: OPTIMIZE and VACUUM per partition\n",
    "\n",
    "4. **Compliance and Retention:**\n",
    "   ```sql\n",
    "   -- Delete old data by partition (GDPR right to be forgotten)\n",
    "   DELETE FROM employees_by_location \n",
    "   WHERE city = 'Paris' AND birth_year < 1970\n",
    "   ```\n",
    "   - **Data retention**: Delete old partitions based on business rules\n",
    "   - **Compliance**: Remove data by geographic region\n",
    "   - **Archival**: Move old partitions to cold storage\n",
    "\n",
    "**Considerations:**\n",
    "\n",
    "5. **Partition Design Best Practices:**\n",
    "   ```sql\n",
    "   -- Good partitioning: balanced, query-aligned\n",
    "   PARTITIONED BY (region, year)  -- ~10-100 partitions each\n",
    "   \n",
    "   -- Poor partitioning: too granular\n",
    "   PARTITIONED BY (employee_id)   -- Thousands of tiny partitions\n",
    "   \n",
    "   -- Poor partitioning: too broad  \n",
    "   PARTITIONED BY (country)       -- Only 3-5 large partitions\n",
    "   ```\n",
    "   - **Cardinality balance**: 10-1000 partitions optimal\n",
    "   - **Query alignment**: Partition keys match common filter patterns\n",
    "   - **Data size**: Each partition 100MB-1GB ideal\n",
    "\n",
    "**Q3: When would you use CTAS vs creating views?**\n",
    "\n",
    "**Answer:**\n",
    "Choose based on performance, complexity, and update patterns:\n",
    "\n",
    "**Use CTAS (Materialized Data) When:**\n",
    "\n",
    "1. **Performance-Critical Scenarios:**\n",
    "   ```sql\n",
    "   -- Heavy aggregation that's queried frequently\n",
    "   CREATE TABLE analytics.daily_revenue_summary AS\n",
    "   SELECT \n",
    "       DATE(order_timestamp) as order_date,\n",
    "       product_category,\n",
    "       SUM(revenue) as total_revenue,\n",
    "       COUNT(*) as order_count,\n",
    "       AVG(revenue) as avg_order_value\n",
    "   FROM sales.orders o\n",
    "   JOIN products.catalog p ON o.product_id = p.id\n",
    "   WHERE order_timestamp >= '2023-01-01'\n",
    "   GROUP BY DATE(order_timestamp), product_category\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Fast queries**: Pre-computed results, no aggregation at query time\n",
    "   - **Consistent performance**: Query time independent of source data size\n",
    "   - **Resource efficiency**: No repeated expensive computations\n",
    "\n",
    "2. **Complex Transformations:**\n",
    "   ```sql\n",
    "   -- Complex business logic that's expensive to compute\n",
    "   CREATE TABLE customer.loyalty_segments AS\n",
    "   WITH customer_metrics AS (\n",
    "     SELECT customer_id,\n",
    "            COUNT(*) as total_orders,\n",
    "            SUM(amount) as lifetime_value,\n",
    "            AVG(DATEDIFF(order_date, LAG(order_date) OVER (PARTITION BY customer_id ORDER BY order_date))) as avg_days_between_orders\n",
    "     FROM orders GROUP BY customer_id\n",
    "   ),\n",
    "   rfm_analysis AS (\n",
    "     SELECT customer_id,\n",
    "            NTILE(5) OVER (ORDER BY recency) as recency_score,\n",
    "            NTILE(5) OVER (ORDER BY frequency) as frequency_score,\n",
    "            NTILE(5) OVER (ORDER BY monetary) as monetary_score\n",
    "     FROM customer_metrics\n",
    "   )\n",
    "   SELECT customer_id, recency_score + frequency_score + monetary_score as loyalty_score\n",
    "   FROM rfm_analysis\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Complexity isolation**: Hide complex logic from end users\n",
    "   - **Debugging**: Intermediate results available for validation\n",
    "   - **Reliability**: Pre-validated transformations\n",
    "\n",
    "3. **Data Stability:**\n",
    "   ```sql\n",
    "   -- Snapshot historical data that changes over time\n",
    "   CREATE TABLE reporting.monthly_snapshot_202310 AS\n",
    "   SELECT customer_id, account_balance, credit_score, risk_category\n",
    "   FROM finance.customer_profiles\n",
    "   WHERE snapshot_date = '2023-10-31'\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Point-in-time consistency**: Results don't change with source data updates\n",
    "   - **Historical preservation**: Maintain historical snapshots\n",
    "   - **Audit compliance**: Fixed data for reporting periods\n",
    "\n",
    "**Use Views When:**\n",
    "\n",
    "1. **Real-Time Requirements:**\n",
    "   ```sql\n",
    "   CREATE VIEW operations.current_system_status AS\n",
    "   SELECT \n",
    "       system_component,\n",
    "       status,\n",
    "       last_heartbeat,\n",
    "       CASE \n",
    "         WHEN last_heartbeat < CURRENT_TIMESTAMP() - INTERVAL 5 MINUTES \n",
    "         THEN 'ALERT' ELSE 'OK' \n",
    "       END as health_status\n",
    "   FROM monitoring.heartbeats\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Always current**: Reflects latest data state\n",
    "   - **No maintenance**: Automatically updates with source changes\n",
    "   - **Real-time insights**: Critical for operational dashboards\n",
    "\n",
    "2. **Security and Access Control:**\n",
    "   ```sql\n",
    "   CREATE VIEW finance.user_accessible_accounts AS\n",
    "   SELECT account_id, account_name, balance\n",
    "   FROM finance.all_accounts a\n",
    "   JOIN security.user_permissions p ON a.account_id = p.account_id\n",
    "   WHERE p.user_id = current_user()\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Dynamic security**: Access based on current user context\n",
    "   - **No data duplication**: Single source of truth\n",
    "   - **Governance**: Centralized access control logic\n",
    "\n",
    "3. **Simple Transformations:**\n",
    "   ```sql\n",
    "   CREATE VIEW sales.readable_orders AS\n",
    "   SELECT \n",
    "       order_id,\n",
    "       customer_name,\n",
    "       order_amount,\n",
    "       order_date,\n",
    "       CASE status_code \n",
    "         WHEN 'P' THEN 'Pending'\n",
    "         WHEN 'S' THEN 'Shipped' \n",
    "         WHEN 'C' THEN 'Completed'\n",
    "       END as order_status\n",
    "   FROM sales.orders_raw\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Low overhead**: Simple transformations don't justify materialization\n",
    "   - **Always synchronized**: No risk of stale data\n",
    "   - **Storage efficient**: No additional storage required\n",
    "\n",
    "**Decision Framework:**\n",
    "- **High query frequency + expensive computation** → CTAS\n",
    "- **Real-time requirements + simple logic** → View  \n",
    "- **Historical snapshots + compliance** → CTAS\n",
    "- **Security layer + access control** → View\n",
    "- **Complex analytics + performance critical** → CTAS\n",
    "- **Data exploration + prototyping** → View\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 5 Solutions: Delta Lake Constraints Implementation\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: What is the difference between enforced constraints and metadata-only constraints?**\n",
    "\n",
    "**Answer:**\n",
    "Delta Lake constraints fall into two categories based on enforcement:\n",
    "\n",
    "**Enforced Constraints (Runtime Enforcement):**\n",
    "\n",
    "These are **actively validated by the Delta Engine at write time**:\n",
    "\n",
    "1. **NOT NULL Constraints:**\n",
    "   ```sql\n",
    "   ALTER TABLE employees ADD CONSTRAINT emp_id_not_null NOT NULL (employee_id)\n",
    "   ```\n",
    "   **Enforcement Details:**\n",
    "   - **WHO**: Delta Engine validates each row during write operations\n",
    "   - **WHEN**: At write time (INSERT, UPDATE, MERGE, streaming writes)\n",
    "   - **RESULT**: Write operation fails if constraint violated\n",
    "   - **PERFORMANCE**: Minimal overhead - simple null checks\n",
    "\n",
    "2. **CHECK Constraints:**\n",
    "   ```sql\n",
    "   ALTER TABLE employees ADD CONSTRAINT salary_positive CHECK (salary > 0)\n",
    "   ALTER TABLE employees ADD CONSTRAINT valid_email CHECK (email LIKE '%@%.%')\n",
    "   ```\n",
    "   **Enforcement Details:**\n",
    "   - **WHO**: Delta Engine evaluates CHECK expression for each row\n",
    "   - **WHEN**: At write time for all write operations  \n",
    "   - **RESULT**: Transaction fails if any row violates constraint\n",
    "   - **PERFORMANCE**: Depends on complexity of CHECK expression\n",
    "\n",
    "**Write-Time Validation Example:**\n",
    "```python\n",
    "# This will fail due to constraint violation\n",
    "df = spark.createDataFrame([(1, None, -50000)], ['id', 'name', 'salary'])\n",
    "df.write.format('delta').mode('append').saveAsTable('employees')\n",
    "# Error: NOT NULL constraint violation (name) and CHECK constraint violation (salary)\n",
    "```\n",
    "\n",
    "**Metadata-Only Constraints (Informational):**\n",
    "\n",
    "These are **stored as metadata** but **not enforced by Delta Engine**:\n",
    "\n",
    "1. **PRIMARY KEY:**\n",
    "   ```sql\n",
    "   ALTER TABLE employees ADD CONSTRAINT pk_employee PRIMARY KEY (employee_id)\n",
    "   ```\n",
    "\n",
    "2. **FOREIGN KEY:**\n",
    "   ```sql\n",
    "   ALTER TABLE orders ADD CONSTRAINT fk_customer \n",
    "   FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
    "   ```\n",
    "\n",
    "3. **UNIQUE:**\n",
    "   ```sql\n",
    "   ALTER TABLE employees ADD CONSTRAINT unique_email UNIQUE (email)\n",
    "   ```\n",
    "\n",
    "**Metadata-Only Details:**\n",
    "- **WHO**: Unity Catalog stores constraint metadata\n",
    "- **WHEN**: Information available for query optimization and governance\n",
    "- **ENFORCEMENT**: None - duplicate/invalid data can be inserted\n",
    "- **PURPOSE**: Documentation, query optimization hints, governance\n",
    "\n",
    "**Constraint Enforcement Comparison:**\n",
    "\n",
    "| Constraint Type | Enforced? | Performance Impact | Use Case |\n",
    "|----------------|-----------|-------------------|----------|\n",
    "| **NOT NULL** | ✅ Yes | Minimal | Data quality |\n",
    "| **CHECK** | ✅ Yes | Low-Medium | Business rules |\n",
    "| **PRIMARY KEY** | ❌ No | None | Documentation |\n",
    "| **FOREIGN KEY** | ❌ No | None | Lineage |\n",
    "| **UNIQUE** | ❌ No | None | Documentation |\n",
    "| **DEFAULT** | ⚠️ Limited | None | SQL INSERT only |\n",
    "\n",
    "**Q2: Why are CHECK constraints enforced at write time by the Delta Engine?**\n",
    "\n",
    "**Answer:**\n",
    "CHECK constraints are enforced at write time for several architectural and performance reasons:\n",
    "\n",
    "1. **ACID Transaction Guarantees:**\n",
    "   ```python\n",
    "   # All-or-nothing approach\n",
    "   try:\n",
    "       df.write.format('delta').mode('append').saveAsTable('employees')\n",
    "       # If ANY row violates CHECK constraint, ENTIRE batch fails\n",
    "       print(\"All data written successfully\")\n",
    "   except Exception as e:\n",
    "       # No partial writes - table remains in consistent state\n",
    "       print(f\"No data written due to constraint violation: {e}\")\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Atomicity**: Either all data passes validation or none is written\n",
    "   - **Consistency**: Table never enters invalid state\n",
    "   - **Data integrity**: Guaranteed constraint compliance\n",
    "\n",
    "2. **Performance Optimization:**\n",
    "   ```sql\n",
    "   -- Constraint checked once during write\n",
    "   ALTER TABLE sales ADD CONSTRAINT positive_amount CHECK (amount > 0)\n",
    "   \n",
    "   -- Query time: No validation overhead\n",
    "   SELECT SUM(amount) FROM sales  -- Optimizer knows amount > 0\n",
    "   ```\n",
    "   **Advantages:**\n",
    "   - **Write-once validation**: Avoid repeated constraint checks on reads\n",
    "   - **Query optimization**: Query planner can use constraint information\n",
    "   - **Read performance**: No runtime validation during queries\n",
    "\n",
    "3. **Distributed System Design:**\n",
    "   ```python\n",
    "   # Validation parallelized across cluster nodes\n",
    "   large_df.repartition(100) \\\n",
    "           .write.format('delta') \\\n",
    "           .mode('append') \\\n",
    "           .saveAsTable('employees')\n",
    "   # Each partition validated independently on different nodes\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Parallel validation**: Constraints checked across cluster nodes\n",
    "   - **Scalability**: Validation scales with data volume\n",
    "   - **Fault tolerance**: Failed partitions don't affect others\n",
    "\n",
    "4. **Data Lake Architecture:**\n",
    "   ```sql\n",
    "   -- Multiple writers, single validation point\n",
    "   INSERT INTO events SELECT * FROM stream_1  -- Writer 1\n",
    "   INSERT INTO events SELECT * FROM stream_2  -- Writer 2  \n",
    "   INSERT INTO events SELECT * FROM batch_3   -- Writer 3\n",
    "   -- All writers subject to same constraints\n",
    "   ```\n",
    "   **Advantages:**\n",
    "   - **Consistency across writers**: All ingestion paths validated equally\n",
    "   - **Schema enforcement**: Prevents schema drift from multiple sources\n",
    "   - **Quality gates**: Central quality control point\n",
    "\n",
    "5. **Integration with Delta Lake Features:**\n",
    "   ```sql\n",
    "   -- Constraints work with all Delta operations\n",
    "   UPDATE employees SET salary = salary * 1.1  -- CHECK constraint applied\n",
    "   MERGE INTO employees USING updates ON ...   -- CHECK constraint applied\n",
    "   COPY INTO employees FROM 's3://data/'       -- CHECK constraint applied\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Universal enforcement**: Works with all write operations\n",
    "   - **Streaming integration**: Real-time constraint validation\n",
    "   - **Batch compatibility**: Same constraints for batch and streaming\n",
    "\n",
    "**Write-Time vs Read-Time Comparison:**\n",
    "\n",
    "| Approach | Pros | Cons |\n",
    "|----------|------|------|\n",
    "| **Write-Time** | Guaranteed data quality, query optimization, performance | Slower writes |\n",
    "| **Read-Time** | Faster writes, flexible validation | Inconsistent data, query overhead |\n",
    "\n",
    "Delta Lake chooses write-time enforcement for **data quality guarantees** over write performance.\n",
    "\n",
    "**Q3: How do constraints contribute to data quality in a data lake?**\n",
    "\n",
    "**Answer:**\n",
    "Constraints are fundamental to maintaining data quality in data lakes:\n",
    "\n",
    "1. **Data Integrity Foundation:**\n",
    "   ```sql\n",
    "   CREATE TABLE customer_profiles (\n",
    "       customer_id INT NOT NULL,\n",
    "       email STRING NOT NULL,\n",
    "       age INT,\n",
    "       signup_date DATE NOT NULL,\n",
    "       CONSTRAINT valid_email CHECK (email LIKE '%@%.%'),\n",
    "       CONSTRAINT reasonable_age CHECK (age >= 0 AND age <= 120),\n",
    "       CONSTRAINT valid_signup CHECK (signup_date >= '2020-01-01')\n",
    "   )\n",
    "   ```\n",
    "   **Quality Benefits:**\n",
    "   - **Completeness**: NOT NULL ensures required data present\n",
    "   - **Validity**: CHECK constraints enforce business rules\n",
    "   - **Consistency**: Uniform data format and ranges\n",
    "\n",
    "2. **Early Error Detection:**\n",
    "   ```python\n",
    "   # Bad data caught at ingestion time\n",
    "   bad_customer_data = [\n",
    "       (None, \"invalid-email\", 150, \"1999-01-01\"),  # Multiple violations\n",
    "       (123, \"valid@email.com\", 25, \"2023-01-01\")   # Valid record\n",
    "   ]\n",
    "   \n",
    "   try:\n",
    "       df = spark.createDataFrame(bad_customer_data, schema)\n",
    "       df.write.format('delta').mode('append').saveAsTable('customer_profiles')\n",
    "   except Exception as e:\n",
    "       print(\"Data quality issues caught before storage:\")\n",
    "       print(\"- NULL customer_id\")\n",
    "       print(\"- Invalid email format\") \n",
    "       print(\"- Age out of range\")\n",
    "       print(\"- Signup date too old\")\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Fail fast**: Problems detected immediately\n",
    "   - **Cost savings**: Avoid processing bad data downstream\n",
    "   - **Debugging**: Clear error messages for data issues\n",
    "\n",
    "3. **Downstream System Protection:**\n",
    "   ```sql\n",
    "   -- Analytics systems can rely on data quality\n",
    "   CREATE VIEW customer_analytics AS\n",
    "   SELECT \n",
    "       AVG(age) as avg_customer_age,        -- Safe: age always valid range\n",
    "       COUNT(*) / COUNT(email) as email_rate -- Always 1.0: email never null\n",
    "   FROM customer_profiles\n",
    "   -- No need for defensive coding - constraints guarantee quality\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Reliable analytics**: Downstream systems trust data quality\n",
    "   - **Simplified code**: No defensive null checks required\n",
    "   - **Accurate metrics**: Quality constraints ensure valid calculations\n",
    "\n",
    "4. **Compliance and Governance:**\n",
    "   ```sql\n",
    "   -- GDPR compliance through constraints\n",
    "   CREATE TABLE user_data (\n",
    "       user_id STRING NOT NULL,\n",
    "       email STRING NOT NULL,\n",
    "       country_code STRING NOT NULL,\n",
    "       data_processing_consent BOOLEAN NOT NULL,\n",
    "       CONSTRAINT valid_country CHECK (country_code IN ('US', 'EU', 'UK', 'CA')),\n",
    "       CONSTRAINT consent_required CHECK (data_processing_consent = true)\n",
    "   )\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Regulatory compliance**: Enforce legal requirements\n",
    "   - **Audit trails**: Provable data quality standards\n",
    "   - **Risk mitigation**: Prevent compliance violations\n",
    "\n",
    "5. **Data Pipeline Reliability:**\n",
    "   ```sql\n",
    "   -- Multi-stage pipeline with quality gates\n",
    "   CREATE TABLE bronze_events (\n",
    "       event_id STRING NOT NULL,\n",
    "       timestamp TIMESTAMP NOT NULL,\n",
    "       user_id STRING NOT NULL,\n",
    "       CONSTRAINT recent_events CHECK (timestamp >= current_date() - INTERVAL 30 DAYS)\n",
    "   )\n",
    "   \n",
    "   CREATE TABLE silver_events (  \n",
    "       event_id STRING NOT NULL,\n",
    "       processed_timestamp TIMESTAMP NOT NULL,\n",
    "       user_id STRING NOT NULL,\n",
    "       event_type STRING NOT NULL,\n",
    "       CONSTRAINT valid_event_type CHECK (event_type IN ('click', 'view', 'purchase'))\n",
    "   )\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Stage validation**: Quality gates at each processing stage\n",
    "   - **Error isolation**: Problems caught before affecting downstream stages\n",
    "   - **Pipeline reliability**: Consistent data flow guaranteed\n",
    "\n",
    "6. **Business Rule Enforcement:**\n",
    "   ```sql\n",
    "   -- Business logic encoded as constraints\n",
    "   CREATE TABLE orders (\n",
    "       order_id STRING NOT NULL,\n",
    "       customer_id STRING NOT NULL, \n",
    "       order_total DECIMAL(10,2) NOT NULL,\n",
    "       discount_amount DECIMAL(10,2),\n",
    "       tax_amount DECIMAL(10,2) NOT NULL,\n",
    "       CONSTRAINT positive_total CHECK (order_total > 0),\n",
    "       CONSTRAINT reasonable_discount CHECK (discount_amount <= order_total * 0.5),\n",
    "       CONSTRAINT valid_tax CHECK (tax_amount >= 0 AND tax_amount <= order_total * 0.3)\n",
    "   )\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Business logic centralization**: Rules enforced at data layer\n",
    "   - **Consistency**: Same rules applied regardless of data source\n",
    "   - **Documentation**: Constraints serve as business rule documentation\n",
    "\n",
    "**Data Quality Impact Measurement:**\n",
    "```sql\n",
    "-- Before constraints: Quality monitoring required\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(*) - COUNT(customer_id) as missing_customer_ids,\n",
    "    COUNT(*) - COUNT(email) as missing_emails,\n",
    "    SUM(CASE WHEN age < 0 OR age > 120 THEN 1 ELSE 0 END) as invalid_ages\n",
    "FROM customer_data\n",
    "\n",
    "-- After constraints: Quality guaranteed  \n",
    "SELECT COUNT(*) as total_records,\n",
    "       0 as data_quality_issues  -- Guaranteed by constraints\n",
    "FROM customer_profiles\n",
    "```\n",
    "\n",
    "**Quality Benefits Summary:**\n",
    "- **Prevention**: Stop bad data at ingestion\n",
    "- **Trust**: Downstream systems can rely on data quality  \n",
    "- **Efficiency**: Eliminate quality checks in every query\n",
    "- **Compliance**: Meet regulatory data quality requirements\n",
    "- **Documentation**: Constraints document quality expectations\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 6 Solutions: Advanced Constraint Scenarios\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: How do complex CHECK constraints help enforce business rules?**\n",
    "\n",
    "**Answer:**\n",
    "Complex CHECK constraints enable sophisticated business rule enforcement:\n",
    "\n",
    "**Multi-Column Business Logic:**\n",
    "```sql\n",
    "CREATE TABLE employee_compensation (\n",
    "    employee_id INT NOT NULL,\n",
    "    base_salary DOUBLE NOT NULL,\n",
    "    bonus_percentage DOUBLE,\n",
    "    commission_rate DOUBLE,\n",
    "    total_compensation DOUBLE,\n",
    "    effective_date DATE NOT NULL,\n",
    "    \n",
    "    -- Complex business rules as constraints\n",
    "    CONSTRAINT salary_bonus_relationship CHECK (\n",
    "        total_compensation >= base_salary * (1 + COALESCE(bonus_percentage, 0) / 100)\n",
    "    ),\n",
    "    CONSTRAINT executive_compensation_limits CHECK (\n",
    "        CASE \n",
    "            WHEN base_salary > 200000 THEN bonus_percentage <= 50\n",
    "            ELSE true\n",
    "        END\n",
    "    ),\n",
    "    CONSTRAINT commission_eligibility CHECK (\n",
    "        CASE \n",
    "            WHEN commission_rate > 0 THEN base_salary >= 50000\n",
    "            ELSE true\n",
    "        END\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "**Business Rule Benefits:**\n",
    "\n",
    "1. **Logical Consistency Enforcement:**\n",
    "   ```sql\n",
    "   -- Ensures total compensation always makes mathematical sense\n",
    "   CONSTRAINT logical_compensation CHECK (\n",
    "       total_compensation >= base_salary + \n",
    "                           COALESCE(base_salary * bonus_percentage / 100, 0)\n",
    "   )\n",
    "   ```\n",
    "   **Prevents:**\n",
    "   - Total compensation less than base salary\n",
    "   - Inconsistent bonus calculations\n",
    "   - Mathematical errors in compensation data\n",
    "\n",
    "2. **Conditional Business Rules:**\n",
    "   ```sql\n",
    "   -- Different rules for different employee categories\n",
    "   CONSTRAINT category_based_rules CHECK (\n",
    "       CASE \n",
    "           WHEN job_level = 'Executive' THEN \n",
    "               base_salary >= 150000 AND bonus_percentage <= 100\n",
    "           WHEN job_level = 'Manager' THEN \n",
    "               base_salary >= 80000 AND bonus_percentage <= 50\n",
    "           WHEN job_level = 'Individual Contributor' THEN \n",
    "               base_salary >= 40000 AND bonus_percentage <= 25\n",
    "           ELSE true\n",
    "       END\n",
    "   )\n",
    "   ```\n",
    "   **Benefits:**\n",
    "   - **Role-appropriate rules**: Different constraints per job level\n",
    "   - **Business hierarchy**: Enforce organizational compensation structure\n",
    "   - **Compliance**: Meet regulatory compensation guidelines\n",
    "\n",
    "3. **Cross-Column Validation:**\n",
    "   ```sql\n",
    "   -- Ensure related fields are consistent\n",
    "   CONSTRAINT sales_role_commission CHECK (\n",
    "       CASE \n",
    "           WHEN department = 'Sales' THEN commission_rate IS NOT NULL\n",
    "           WHEN department != 'Sales' THEN commission_rate IS NULL OR commission_rate = 0\n",
    "           ELSE true\n",
    "       END\n",
    "   )\n",
    "   ```\n",
    "   **Enforces:**\n",
    "   - Sales employees must have commission structure\n",
    "   - Non-sales employees cannot earn commission\n",
    "   - Department-specific compensation models\n",
    "\n",
    "4. **Temporal Business Rules:**\n",
    "   ```sql\n",
    "   CONSTRAINT compensation_change_limits CHECK (\n",
    "       CASE \n",
    "           WHEN effective_date > '2023-01-01' THEN \n",
    "               total_compensation <= base_salary * 3  -- Recent hire limits\n",
    "           ELSE true  -- Grandfathered employees exempt\n",
    "       END\n",
    "   )\n",
    "   ```\n",
    "   **Capabilities:**\n",
    "   - **Time-based rules**: Different rules for different periods\n",
    "   - **Grandfathering**: Exempt existing records from new rules\n",
    "   - **Regulatory changes**: Implement new compliance requirements\n",
    "\n",
    "**Real-World Business Rule Examples:**\n",
    "```sql\n",
    "-- Financial services compliance\n",
    "CREATE TABLE loan_applications (\n",
    "    application_id STRING NOT NULL,\n",
    "    loan_amount DECIMAL(12,2) NOT NULL,\n",
    "    annual_income DECIMAL(12,2) NOT NULL,\n",
    "    debt_to_income_ratio DECIMAL(5,4),\n",
    "    credit_score INT,\n",
    "    loan_purpose STRING NOT NULL,\n",
    "    \n",
    "    -- Regulatory compliance constraints\n",
    "    CONSTRAINT debt_to_income_limit CHECK (\n",
    "        debt_to_income_ratio <= 0.43  -- Federal regulation\n",
    "    ),\n",
    "    CONSTRAINT loan_to_income_ratio CHECK (\n",
    "        loan_amount <= annual_income * 5  -- Internal risk policy\n",
    "    ),\n",
    "    CONSTRAINT credit_score_requirements CHECK (\n",
    "        CASE loan_purpose\n",
    "            WHEN 'mortgage' THEN credit_score >= 620\n",
    "            WHEN 'auto' THEN credit_score >= 580\n",
    "            WHEN 'personal' THEN credit_score >= 640\n",
    "            ELSE credit_score >= 500\n",
    "        END\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "**Q2: What happens when multiple constraints are violated simultaneously?**\n",
    "\n",
    "**Answer:**\n",
    "When multiple constraints are violated, Delta Lake's behavior is specific and predictable:\n",
    "\n",
    "**Constraint Evaluation Order:**\n",
    "```python\n",
    "# Test data violating multiple constraints\n",
    "test_data = [(\n",
    "    1,          # employee_id: OK\n",
    "    -50000.0,   # base_salary: ❌ Violates positive_base_salary CHECK\n",
    "    150.0,      # bonus_percentage: ❌ Violates reasonable_bonus CHECK (>100)\n",
    "    60.0,       # commission_rate: ❌ Violates reasonable_commission CHECK (>50)\n",
    "    -40000.0,   # total_compensation: ❌ Violates logical_compensation CHECK \n",
    "    \"2019-01-01\"  # effective_date: ❌ Violates future_effective_date CHECK\n",
    ")]\n",
    "```\n",
    "\n",
    "**Error Behavior:**\n",
    "\n",
    "1. **First Violation Reported:**\n",
    "```python\n",
    "try:\n",
    "    df.write.format('delta').mode('append').saveAsTable('employee_compensation')\n",
    "except Exception as e:\n",
    "    print(\"Delta Lake reports first constraint violation encountered:\")\n",
    "    print(e)\n",
    "    # Output: \"CHECK constraint positive_base_salary violated by row...\"\n",
    "    # Other violations not reported until first is fixed\n",
    "```\n",
    "\n",
    "**Sequential Constraint Fixing:**\n",
    "```python\n",
    "# Fix constraints one by one\n",
    "test_cases = [\n",
    "    # Fix 1: Positive base salary\n",
    "    (1, 50000.0, 150.0, 60.0, -40000.0, \"2019-01-01\"),\n",
    "    # Next error: \"CHECK constraint reasonable_bonus violated...\"\n",
    "    \n",
    "    # Fix 2: Reasonable bonus  \n",
    "    (1, 50000.0, 50.0, 60.0, -40000.0, \"2019-01-01\"),\n",
    "    # Next error: \"CHECK constraint reasonable_commission violated...\"\n",
    "    \n",
    "    # Fix 3: Reasonable commission\n",
    "    (1, 50000.0, 50.0, 25.0, -40000.0, \"2019-01-01\"),\n",
    "    # Next error: \"CHECK constraint logical_compensation violated...\"\n",
    "    \n",
    "    # Fix 4: Logical compensation\n",
    "    (1, 50000.0, 50.0, 25.0, 75000.0, \"2019-01-01\"),\n",
    "    # Next error: \"CHECK constraint future_effective_date violated...\"\n",
    "    \n",
    "    # Fix 5: Valid effective date\n",
    "    (1, 50000.0, 50.0, 25.0, 75000.0, \"2023-01-01\"),\n",
    "    # Success: All constraints satisfied\n",
    "]\n",
    "```\n",
    "\n",
    "2. **Batch Behavior:**\n",
    "```python\n",
    "# Multiple rows: First violation in batch stops entire operation\n",
    "mixed_batch = [\n",
    "    (1, 60000.0, 10.0, 5.0, 66000.0, \"2023-01-01\"),  # ✅ Valid\n",
    "    (2, -30000.0, 5.0, 2.0, -28500.0, \"2023-02-01\"),  # ❌ Invalid salary\n",
    "    (3, 80000.0, 15.0, 8.0, 92000.0, \"2023-03-01\"),  # ✅ Valid (never processed)\n",
    "]\n",
    "# Result: NO rows inserted - entire batch fails\n",
    "```\n",
    "\n",
    "3. **Multiple Constraint Names in Error:**\n",
    "```sql\n",
    "-- Some constraint violations may mention related constraints\n",
    "ALTER TABLE test_table ADD CONSTRAINT rule1 CHECK (a > 0)\n",
    "ALTER TABLE test_table ADD CONSTRAINT rule2 CHECK (b > a)\n",
    "\n",
    "-- Insert violates both: a = -1, b = -2  \n",
    "-- Error may reference both rule1 and rule2 if they're interdependent\n",
    "```\n",
    "\n",
    "**Best Practices for Multiple Constraints:**\n",
    "\n",
    "1. **Constraint Testing Strategy:**\n",
    "```python\n",
    "def test_constraints_individually():\n",
    "    \"\"\"Test each constraint violation separately for debugging\"\"\"\n",
    "    \n",
    "    base_valid_record = (1, 60000.0, 10.0, 5.0, 66000.0, \"2023-01-01\")\n",
    "    \n",
    "    constraint_tests = [\n",
    "        # Test each constraint individually\n",
    "        (1, -1000.0, 10.0, 5.0, 66000.0, \"2023-01-01\"),   # salary constraint\n",
    "        (1, 60000.0, 200.0, 5.0, 66000.0, \"2023-01-01\"),  # bonus constraint  \n",
    "        (1, 60000.0, 10.0, 100.0, 66000.0, \"2023-01-01\"), # commission constraint\n",
    "        (1, 60000.0, 10.0, 5.0, 50000.0, \"2023-01-01\"),   # total comp constraint\n",
    "        (1, 60000.0, 10.0, 5.0, 66000.0, \"2018-01-01\"),   # date constraint\n",
    "    ]\n",
    "    \n",
    "    for test_record in constraint_tests:\n",
    "        try:\n",
    "            test_df = spark.createDataFrame([test_record], schema)\n",
    "            test_df.write.format('delta').mode('overwrite').saveAsTable('temp_test')\n",
    "            print(f\"✅ Constraint test passed: {test_record}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Constraint violation: {str(e)[:100]}...\")\n",
    "```\n",
    "\n",
    "2. **Comprehensive Data Validation:**\n",
    "```python\n",
    "def validate_before_insert(df):\n",
    "    \"\"\"Pre-validate data against known constraints to identify all issues\"\"\"\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check each constraint manually\n",
    "    negative_salary = df.filter(col(\"base_salary\") <= 0).count()\n",
    "    if negative_salary > 0:\n",
    "        issues.append(f\"{negative_salary} records with negative/zero salary\")\n",
    "    \n",
    "    invalid_bonus = df.filter(col(\"bonus_percentage\") > 100).count() \n",
    "    if invalid_bonus > 0:\n",
    "        issues.append(f\"{invalid_bonus} records with bonus > 100%\")\n",
    "    \n",
    "    # Report all issues before attempting insert\n",
    "    if issues:\n",
    "        print(\"Data quality issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "        return False\n",
    "    return True\n",
    "```\n",
    "\n",
    "**Practical Impact:**\n",
    "- **Development**: Fix constraints one at a time during testing\n",
    "- **Production**: Implement comprehensive data validation before writes  \n",
    "- **Monitoring**: Alert on constraint violations to catch data quality issues\n",
    "- **Documentation**: Clearly document constraint dependencies\n",
    "\n",
    "**Q3: How would you design constraints for a real-world scenario?**\n",
    "\n",
    "**Answer:**\n",
    "Designing effective constraints requires balancing data quality, performance, and business requirements:\n",
    "\n",
    "**Real-World Scenario: E-commerce Order Management System**\n",
    "\n",
    "**1. Requirement Analysis:**\n",
    "```sql\n",
    "-- Business Requirements Analysis:\n",
    "-- - Orders must have valid customers and products\n",
    "-- - Order amounts must be positive and reasonable  \n",
    "-- - Discounts cannot exceed order value\n",
    "-- - Shipping addresses are required for physical products\n",
    "-- - Order dates must be reasonable (not future, not too old)\n",
    "-- - Tax calculations must be within expected ranges\n",
    "-- - Order status follows valid state transitions\n",
    "```\n",
    "\n",
    "**2. Hierarchical Constraint Design:**\n",
    "\n",
    "**Core Data Integrity (NOT NULL):**\n",
    "```sql\n",
    "CREATE TABLE ecommerce_orders (\n",
    "    order_id STRING NOT NULL,           -- Always required\n",
    "    customer_id STRING NOT NULL,        -- Always required  \n",
    "    order_date DATE NOT NULL,           -- Always required\n",
    "    order_status STRING NOT NULL,       -- Always required\n",
    "    subtotal DECIMAL(12,2) NOT NULL,    -- Always required\n",
    "    tax_amount DECIMAL(12,2) NOT NULL,  -- Always required\n",
    "    total_amount DECIMAL(12,2) NOT NULL -- Always required\n",
    "    -- ... other columns\n",
    ")\n",
    "```\n",
    "\n",
    "**Business Logic Constraints (CHECK):**\n",
    "```sql\n",
    "-- Level 1: Basic validity checks\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT positive_amounts \n",
    "CHECK (subtotal >= 0 AND tax_amount >= 0 AND total_amount >= 0);\n",
    "\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT reasonable_order_dates\n",
    "CHECK (order_date >= '2020-01-01' AND order_date <= CURRENT_DATE() + INTERVAL 1 DAY);\n",
    "\n",
    "-- Level 2: Mathematical consistency  \n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT amount_consistency\n",
    "CHECK (total_amount >= subtotal AND total_amount <= subtotal + tax_amount + shipping_fee);\n",
    "\n",
    "-- Level 3: Business rule enforcement\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT valid_order_status\n",
    "CHECK (order_status IN ('pending', 'confirmed', 'shipped', 'delivered', 'cancelled', 'returned'));\n",
    "\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT reasonable_discount\n",
    "CHECK (discount_amount IS NULL OR (discount_amount >= 0 AND discount_amount <= subtotal * 0.9));\n",
    "\n",
    "-- Level 4: Complex business scenarios\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT shipping_logic\n",
    "CHECK (\n",
    "    CASE \n",
    "        WHEN product_type = 'digital' THEN shipping_fee = 0 AND shipping_address IS NULL\n",
    "        WHEN product_type = 'physical' THEN shipping_fee >= 0 AND shipping_address IS NOT NULL\n",
    "        ELSE true\n",
    "    END\n",
    ");\n",
    "```\n",
    "\n",
    "**3. Performance-Conscious Design:**\n",
    "\n",
    "**Simple vs Complex Constraints:**\n",
    "```sql\n",
    "-- ✅ Good: Simple, fast constraints\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT order_id_format\n",
    "CHECK (order_id LIKE 'ORD-%' AND LENGTH(order_id) = 15);\n",
    "\n",
    "-- ⚠️ Careful: More expensive constraints\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT tax_rate_validation  \n",
    "CHECK (\n",
    "    CASE \n",
    "        WHEN shipping_state IN ('CA', 'NY', 'TX') THEN \n",
    "            tax_amount BETWEEN subtotal * 0.06 AND subtotal * 0.11\n",
    "        WHEN shipping_state IN ('OR', 'NH', 'MT') THEN\n",
    "            tax_amount = 0\n",
    "        ELSE \n",
    "            tax_amount BETWEEN 0 AND subtotal * 0.15\n",
    "    END\n",
    ");\n",
    "\n",
    "-- ❌ Avoid: Subquery constraints (very expensive)\n",
    "-- CHECK (customer_id IN (SELECT customer_id FROM customers WHERE status = 'active'))\n",
    "```\n",
    "\n",
    "**4. Constraint Evolution Strategy:**\n",
    "\n",
    "**Phase 1: Basic Constraints (Launch)**\n",
    "```sql\n",
    "-- Start with essential constraints only\n",
    "CREATE TABLE ecommerce_orders_v1 (\n",
    "    order_id STRING NOT NULL,\n",
    "    customer_id STRING NOT NULL,\n",
    "    total_amount DECIMAL(12,2) NOT NULL,\n",
    "    CONSTRAINT positive_total CHECK (total_amount > 0),\n",
    "    CONSTRAINT valid_order_id CHECK (order_id LIKE 'ORD-%')\n",
    ");\n",
    "```\n",
    "\n",
    "**Phase 2: Enhanced Validation (Post-Launch)**\n",
    "```sql\n",
    "-- Add business rule constraints after system stabilizes\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT status_validation\n",
    "CHECK (order_status IN ('pending', 'confirmed', 'shipped', 'delivered'));\n",
    "\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT discount_limits  \n",
    "CHECK (discount_amount <= subtotal * 0.5);\n",
    "```\n",
    "\n",
    "**Phase 3: Advanced Business Logic (Mature System)**\n",
    "```sql\n",
    "-- Add complex constraints after understanding data patterns\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT shipping_business_rules\n",
    "CHECK (\n",
    "    CASE shipping_method\n",
    "        WHEN 'overnight' THEN shipping_fee >= 15.00\n",
    "        WHEN 'express' THEN shipping_fee >= 8.00  \n",
    "        WHEN 'standard' THEN shipping_fee >= 0.00\n",
    "        ELSE true\n",
    "    END\n",
    ");\n",
    "```\n",
    "\n",
    "**5. Error Handling and User Experience:**\n",
    "\n",
    "**Meaningful Constraint Names:**\n",
    "```sql\n",
    "-- ✅ Good: Descriptive constraint names\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT order_amount_positive \n",
    "CHECK (total_amount > 0);\n",
    "\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT discount_not_exceeds_subtotal\n",
    "CHECK (discount_amount <= subtotal);\n",
    "\n",
    "-- ❌ Poor: Generic constraint names  \n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT chk_1 CHECK (total_amount > 0);\n",
    "ALTER TABLE ecommerce_orders ADD CONSTRAINT chk_2 CHECK (discount_amount <= subtotal);\n",
    "```\n",
    "\n",
    "**6. Testing and Validation Strategy:**\n",
    "\n",
    "**Comprehensive Test Suite:**\n",
    "```python\n",
    "def test_order_constraints():\n",
    "    \"\"\"Comprehensive constraint testing for e-commerce orders\"\"\"\n",
    "    \n",
    "    # Valid baseline order\n",
    "    valid_order = {\n",
    "        \"order_id\": \"ORD-2023-001234\",\n",
    "        \"customer_id\": \"CUST-567890\",\n",
    "        \"order_date\": \"2023-10-15\",\n",
    "        \"subtotal\": 100.00,\n",
    "        \"tax_amount\": 8.50,\n",
    "        \"shipping_fee\": 5.99,\n",
    "        \"discount_amount\": 10.00,\n",
    "        \"total_amount\": 104.49,\n",
    "        \"order_status\": \"pending\"\n",
    "    }\n",
    "    \n",
    "    # Test each constraint systematically\n",
    "    constraint_tests = [\n",
    "        # Positive amounts\n",
    "        {**valid_order, \"total_amount\": -50.00},  # Should fail\n",
    "        \n",
    "        # Date validation\n",
    "        {**valid_order, \"order_date\": \"2025-12-31\"},  # Should fail (future)\n",
    "        {**valid_order, \"order_date\": \"2019-01-01\"},  # Should fail (too old)\n",
    "        \n",
    "        # Amount consistency\n",
    "        {**valid_order, \"total_amount\": 50.00},  # Should fail (less than subtotal)\n",
    "        \n",
    "        # Valid status\n",
    "        {**valid_order, \"order_status\": \"invalid_status\"},  # Should fail\n",
    "        \n",
    "        # Discount validation  \n",
    "        {**valid_order, \"discount_amount\": 150.00},  # Should fail (exceeds subtotal)\n",
    "    ]\n",
    "    \n",
    "    return run_constraint_tests(constraint_tests)\n",
    "```\n",
    "\n",
    "**7. Monitoring and Maintenance:**\n",
    "\n",
    "**Constraint Monitoring Dashboard:**\n",
    "```sql\n",
    "CREATE VIEW constraint_monitoring AS\n",
    "SELECT \n",
    "    'ecommerce_orders' as table_name,\n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(CASE WHEN total_amount <= 0 THEN 1 END) as negative_amounts,\n",
    "    COUNT(CASE WHEN order_date > CURRENT_DATE() THEN 1 END) as future_orders,\n",
    "    COUNT(CASE WHEN discount_amount > subtotal THEN 1 END) as invalid_discounts,\n",
    "    MAX(order_date) as latest_order_date,\n",
    "    MIN(order_date) as earliest_order_date,\n",
    "    CURRENT_TIMESTAMP() as check_timestamp\n",
    "FROM ecommerce_orders;\n",
    "```\n",
    "\n",
    "**Design Principles Summary:**\n",
    "1. **Start Simple**: Begin with essential constraints, add complexity gradually\n",
    "2. **Business Alignment**: Constraints should reflect actual business rules\n",
    "3. **Performance Balance**: Consider constraint evaluation cost vs. benefit\n",
    "4. **Clear Naming**: Use descriptive constraint names for debugging\n",
    "5. **Systematic Testing**: Test each constraint individually and in combination\n",
    "6. **Evolution Strategy**: Plan for constraint changes as business evolves\n",
    "7. **Monitoring**: Continuously monitor constraint violations and data quality\n",
    "\n",
    "This approach ensures constraints effectively enforce data quality while maintaining system performance and operational flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 7 Solutions: Data Governance and Best Practices\n",
    "\n",
    "### Questions & Answers\n",
    "\n",
    "**Q1: How do table properties contribute to data governance?**\n",
    "\n",
    "**Answer:**\n",
    "Table properties are critical metadata that enables comprehensive data governance:\n",
    "\n",
    "**1. Data Classification and Security:**\n",
    "```sql\n",
    "ALTER TABLE hr_analytics_lab.hr_data.employees_managed \n",
    "SET TBLPROPERTIES (\n",
    "    'data_classification' = 'PII',\n",
    "    'sensitivity_level' = 'high',\n",
    "    'encryption_required' = 'true',\n",
    "    'access_control_required' = 'rbac'\n",
    ");\n",
    "```\n",
    "**Governance Benefits:**\n",
    "- **Automated Security**: Security tools can automatically apply encryption and access controls\n",
    "- **Compliance Scanning**: Automated discovery of sensitive data for GDPR, HIPAA compliance\n",
    "- **Risk Assessment**: Identify high-risk tables requiring additional protection\n",
    "- **Audit Preparation**: Quickly locate all PII data for regulatory audits\n",
    "\n",
    "**2. Data Ownership and Stewardship:**\n",
    "```sql\n",
    "ALTER TABLE sales_data.customer_orders\n",
    "SET TBLPROPERTIES (\n",
    "    'data_steward' = 'sales_analytics_team',\n",
    "    'business_owner' = 'chief_revenue_officer',  \n",
    "    'technical_contact' = 'data_engineering@company.com',\n",
    "    'created_by' = 'etl_pipeline_v2.1',\n",
    "    'cost_center' = 'sales_department'\n",
    ");\n",
    "```\n",
    "**Governance Benefits:**\n",
    "- **Accountability**: Clear ownership chain for data issues\n",
    "- **Contact Information**: Quick resolution of data problems\n",
    "- **Cost Allocation**: Charge storage and compute costs to appropriate departments\n",
    "- **Change Management**: Know who to contact before modifying table structure\n",
    "\n",
    "**3. Data Quality and Reliability:**\n",
    "```sql\n",
    "ALTER TABLE analytics.customer_360_view\n",
    "SET TBLPROPERTIES (\n",
    "    'quality_score' = '94.5',\n",
    "    'last_quality_check' = '2023-10-15',\n",
    "    'data_freshness' = 'daily',\n",
    "    'sla_tier' = 'gold',\n",
    "    'quality_rules' = 'completeness>95%,accuracy>90%,consistency>98%'\n",
    ");\n",
    "```\n",
    "**Governance Benefits:**\n",
    "- **Quality Monitoring**: Automated alerts when quality scores drop\n",
    "- **SLA Management**: Different service levels for different business importance\n",
    "- **Trust Indicators**: Users can assess data reliability before use\n",
    "- **Quality Tracking**: Historical quality trends for improvement initiatives\n",
    "\n",
    "**4. Regulatory and Compliance Metadata:**\n",
    "```sql\n",
    "ALTER TABLE finance.transaction_records  \n",
    "SET TBLPROPERTIES (\n",
    "    'retention_policy' = '7_years',\n",
    "    'retention_start_date' = '2023-01-01',\n",
    "    'regulatory_framework' = 'SOX,PCI_DSS',\n",
    "    'audit_required' = 'quarterly',\n",
    "    'deletion_allowed' = 'false',\n",
    "    'right_to_be_forgotten' = 'customer_id_based'\n",
    ");\n",
    "```\n",
    "**Governance Benefits:**\n",
    "- **Automated Retention**: Policies enforced by data lifecycle management tools\n",
    "- **Compliance Reporting**: Generate compliance status reports automatically  \n",
    "- **Legal Hold**: Prevent data deletion during legal proceedings\n",
    "- **GDPR Compliance**: Support right to be forgotten requests\n",
    "\n",
    "**5. Operational Metadata:**\n",
    "```sql\n",
    "ALTER TABLE streaming.event_logs\n",
    "SET TBLPROPERTIES (\n",
    "    'update_frequency' = 'real_time',\n",
    "    'source_system' = 'kafka_cluster_prod',\n",
    "    'downstream_dependencies' = 'dashboard_daily,ml_model_training',\n",
    "    'backup_schedule' = 'hourly',\n",
    "    'disaster_recovery_rto' = '15_minutes'\n",
    ");\n",
    "```\n",
    "**Governance Benefits:**\n",
    "- **Impact Analysis**: Understand downstream effects of changes\n",
    "- **Capacity Planning**: Right-size infrastructure based on usage patterns\n",
    "- **Incident Response**: Faster troubleshooting with operational context\n",
    "- **Change Coordination**: Coordinate changes across dependent systems\n",
    "\n",
    "**Q2: What metadata should you track for production tables?**\n",
    "\n",
    "**Answer:**\n",
    "Production tables require comprehensive metadata tracking across multiple dimensions:\n",
    "\n",
    "**Essential Production Metadata Categories:**\n",
    "\n",
    "**1. Identity and Classification:**\n",
    "```sql\n",
    "-- Core identification metadata\n",
    "'table_name' = 'customer_transactions',\n",
    "'table_purpose' = 'Financial transaction records for customer billing',\n",
    "'business_domain' = 'finance',\n",
    "'data_classification' = 'confidential_financial',\n",
    "'criticality_tier' = 'tier_1_critical',\n",
    "'table_type' = 'fact_table'\n",
    "```\n",
    "\n",
    "**2. Ownership and Contacts:**\n",
    "```sql  \n",
    "-- Accountability metadata\n",
    "'data_steward' = 'finance_data_team',\n",
    "'business_owner' = 'cfo_organization', \n",
    "'technical_owner' = 'data_platform_team',\n",
    "'on_call_contact' = 'data_engineering_oncall@company.com',\n",
    "'escalation_path' = 'data_lead->engineering_manager->vp_engineering'\n",
    "```\n",
    "\n",
    "**3. Data Quality and SLA:**\n",
    "```sql\n",
    "-- Quality and reliability metadata\n",
    "'sla_tier' = 'platinum',  -- platinum/gold/silver/bronze\n",
    "'availability_sla' = '99.9%',\n",
    "'freshness_sla' = '15_minutes',\n",
    "'quality_score_threshold' = '95%',\n",
    "'completeness_sla' = '99%',\n",
    "'accuracy_sla' = '98%',\n",
    "'last_quality_check' = '2023-10-15T14:30:00Z',\n",
    "'quality_check_frequency' = 'hourly'\n",
    "```\n",
    "\n",
    "**4. Security and Compliance:**\n",
    "```sql\n",
    "-- Security and regulatory metadata  \n",
    "'contains_pii' = 'true',\n",
    "'pii_columns' = 'customer_email,customer_phone,billing_address',\n",
    "'encryption_at_rest' = 'aes_256',\n",
    "'encryption_in_transit' = 'tls_1.3',\n",
    "'access_control_model' = 'rbac_with_abac',\n",
    "'regulatory_frameworks' = 'SOX,PCI_DSS,GDPR',\n",
    "'data_residency_requirements' = 'US_only',\n",
    "'retention_period' = '2555_days'  -- 7 years\n",
    "```\n",
    "\n",
    "**5. Operational Characteristics:**\n",
    "```sql\n",
    "-- Operational metadata\n",
    "'source_system' = 'payment_processing_api',\n",
    "'ingestion_pattern' = 'streaming_kafka',\n",
    "'update_frequency' = 'real_time',\n",
    "'batch_size' = '10000_records_per_minute',\n",
    "'peak_usage_hours' = '09:00-17:00_EST',\n",
    "'backup_frequency' = 'hourly',\n",
    "'backup_retention' = '90_days',\n",
    "'disaster_recovery_rpo' = '5_minutes',\n",
    "'disaster_recovery_rto' = '30_minutes'\n",
    "```\n",
    "\n",
    "**6. Dependencies and Lineage:**\n",
    "```sql  \n",
    "-- Dependency metadata\n",
    "'upstream_tables' = 'raw_events.payment_events,reference.customer_master',\n",
    "'downstream_tables' = 'analytics.daily_revenue,ml.fraud_detection_features',\n",
    "'dependent_dashboards' = 'finance_dashboard,executive_kpis',\n",
    "'dependent_ml_models' = 'fraud_detection_v2,churn_prediction_v3',\n",
    "'api_consumers' = 'billing_service,customer_portal'\n",
    "```\n",
    "\n",
    "**7. Performance and Optimization:**\n",
    "```sql\n",
    "-- Performance metadata\n",
    "'partition_strategy' = 'date_based_monthly',\n",
    "'optimization_schedule' = 'weekly_sunday_02:00',\n",
    "'vacuum_schedule' = 'weekly_sunday_04:00', \n",
    "'expected_daily_growth' = '50_gb',\n",
    "'query_patterns' = 'mostly_recent_data_90_days',\n",
    "'indexing_strategy' = 'bloom_filter_on_customer_id'\n",
    "```\n",
    "\n",
    "**8. Change Management:**\n",
    "```sql\n",
    "-- Change tracking metadata\n",
    "'schema_version' = 'v2.3',\n",
    "'last_schema_change' = '2023-09-15T10:00:00Z',\n",
    "'schema_change_frequency' = 'monthly',\n",
    "'breaking_change_notification_period' = '30_days',\n",
    "'change_approval_required' = 'true',\n",
    "'change_approval_group' = 'data_architecture_board'\n",
    "```\n",
    "\n",
    "**Metadata Implementation Strategy:**\n",
    "\n",
    "**1. Automated Metadata Collection:**\n",
    "```python\n",
    "def collect_table_metadata(table_name):\n",
    "    \"\"\"Automated collection of operational metadata\"\"\"\n",
    "    \n",
    "    # Collect from system tables\n",
    "    details = spark.sql(f\"DESCRIBE DETAIL {table_name}\").collect()[0]\n",
    "    history = spark.sql(f\"DESCRIBE HISTORY {table_name}\").collect()\n",
    "    \n",
    "    auto_metadata = {\n",
    "        'current_size_bytes': details['sizeInBytes'],\n",
    "        'num_files': details['numFiles'], \n",
    "        'last_modified': details['lastModified'],\n",
    "        'version_count': len(history),\n",
    "        'creation_date': min(h['timestamp'] for h in history),\n",
    "        'last_write_operation': history[0]['operation'] if history else 'unknown'\n",
    "    }\n",
    "    \n",
    "    return auto_metadata\n",
    "```\n",
    "\n",
    "**2. Metadata Validation and Monitoring:**\n",
    "```sql\n",
    "-- Create metadata validation view\n",
    "CREATE VIEW data_governance.metadata_completeness AS\n",
    "SELECT \n",
    "    table_catalog,\n",
    "    table_schema, \n",
    "    table_name,\n",
    "    CASE WHEN table_properties['data_steward'] IS NOT NULL THEN 1 ELSE 0 END as has_steward,\n",
    "    CASE WHEN table_properties['sla_tier'] IS NOT NULL THEN 1 ELSE 0 END as has_sla,\n",
    "    CASE WHEN table_properties['data_classification'] IS NOT NULL THEN 1 ELSE 0 END as has_classification,\n",
    "    CASE WHEN table_properties['retention_policy'] IS NOT NULL THEN 1 ELSE 0 END as has_retention,\n",
    "    (has_steward + has_sla + has_classification + has_retention) / 4.0 as metadata_completeness_score\n",
    "FROM information_schema.tables\n",
    "WHERE table_type = 'MANAGED'\n",
    "```\n",
    "\n",
    "**3. Metadata Governance Dashboard:**\n",
    "```sql\n",
    "-- Production readiness assessment\n",
    "CREATE VIEW data_governance.production_readiness AS\n",
    "SELECT \n",
    "    table_name,\n",
    "    CASE \n",
    "        WHEN metadata_completeness_score >= 0.9 THEN 'Production Ready'\n",
    "        WHEN metadata_completeness_score >= 0.7 THEN 'Needs Minor Updates'\n",
    "        WHEN metadata_completeness_score >= 0.5 THEN 'Needs Major Updates'\n",
    "        ELSE 'Not Production Ready'\n",
    "    END as readiness_status,\n",
    "    CASE WHEN table_properties['last_quality_check'] > CURRENT_TIMESTAMP() - INTERVAL 24 HOURS \n",
    "         THEN 'Recent' ELSE 'Outdated' END as quality_check_status\n",
    "FROM data_governance.metadata_completeness\n",
    "```\n",
    "\n",
    "**Q3: How do Unity Catalog constraints support compliance requirements?**\n",
    "\n",
    "**Answer:**\n",
    "Unity Catalog constraints provide foundational support for regulatory compliance:\n",
    "\n",
    "**1. GDPR (General Data Protection Regulation) Support:**\n",
    "\n",
    "**Right to Data Quality:**\n",
    "```sql\n",
    "-- Ensure personal data quality through constraints\n",
    "CREATE TABLE customer_profiles (\n",
    "    customer_id STRING NOT NULL,\n",
    "    email STRING NOT NULL,\n",
    "    phone STRING,\n",
    "    birth_date DATE,\n",
    "    country STRING NOT NULL,\n",
    "    \n",
    "    -- GDPR Article 5: Data quality principles\n",
    "    CONSTRAINT valid_email_format CHECK (email LIKE '%@%.%'),\n",
    "    CONSTRAINT reasonable_birth_date CHECK (birth_date >= '1900-01-01' AND birth_date <= CURRENT_DATE()),\n",
    "    CONSTRAINT valid_country_code CHECK (LENGTH(country) = 2),\n",
    "    \n",
    "    -- Metadata for GDPR compliance\n",
    "    consent_timestamp TIMESTAMP NOT NULL,\n",
    "    data_processing_purpose STRING NOT NULL,\n",
    "    \n",
    "    CONSTRAINT valid_consent CHECK (consent_timestamp <= CURRENT_TIMESTAMP()),\n",
    "    CONSTRAINT valid_purpose CHECK (data_processing_purpose IN (\n",
    "        'service_delivery', 'marketing_consent', 'legal_obligation', 'legitimate_interest'\n",
    "    ))\n",
    ") \n",
    "TBLPROPERTIES (\n",
    "    'contains_pii' = 'true',\n",
    "    'gdpr_lawful_basis' = 'consent,contract',\n",
    "    'retention_period' = '2555_days',  -- 7 years\n",
    "    'deletion_on_request' = 'customer_id_based'\n",
    ");\n",
    "```\n",
    "\n",
    "**Right to be Forgotten Implementation:**\n",
    "```sql\n",
    "-- Constraints supporting data subject rights\n",
    "CREATE TABLE data_deletion_requests (\n",
    "    request_id STRING NOT NULL,\n",
    "    customer_id STRING NOT NULL,\n",
    "    request_date DATE NOT NULL,\n",
    "    request_type STRING NOT NULL,\n",
    "    processing_status STRING NOT NULL,\n",
    "    \n",
    "    -- Ensure proper deletion workflow\n",
    "    CONSTRAINT valid_request_type CHECK (request_type IN ('deletion', 'anonymization', 'data_export')),\n",
    "    CONSTRAINT valid_status CHECK (processing_status IN ('pending', 'in_progress', 'completed', 'rejected')),\n",
    "    CONSTRAINT recent_request CHECK (request_date >= CURRENT_DATE() - INTERVAL 1000 DAYS),\n",
    "    \n",
    "    -- Compliance timing requirements\n",
    "    completion_deadline DATE,\n",
    "    CONSTRAINT gdpr_deadline CHECK (\n",
    "        CASE WHEN request_type = 'deletion' \n",
    "             THEN completion_deadline <= request_date + INTERVAL 30 DAYS\n",
    "             ELSE true END\n",
    "    )\n",
    ");\n",
    "```\n",
    "\n",
    "**2. SOX (Sarbanes-Oxley) Compliance:**\n",
    "\n",
    "**Financial Data Integrity:**\n",
    "```sql\n",
    "-- SOX Section 404: Internal controls over financial reporting\n",
    "CREATE TABLE financial_transactions (\n",
    "    transaction_id STRING NOT NULL,\n",
    "    account_id STRING NOT NULL,\n",
    "    transaction_date DATE NOT NULL,\n",
    "    amount DECIMAL(15,2) NOT NULL,\n",
    "    transaction_type STRING NOT NULL,\n",
    "    created_by STRING NOT NULL,\n",
    "    approved_by STRING,\n",
    "    audit_trail_id STRING NOT NULL,\n",
    "    \n",
    "    -- SOX data integrity constraints\n",
    "    CONSTRAINT positive_amounts CHECK (ABS(amount) > 0),\n",
    "    CONSTRAINT valid_transaction_types CHECK (\n",
    "        transaction_type IN ('debit', 'credit', 'adjustment', 'reversal')\n",
    "    ),\n",
    "    CONSTRAINT recent_transactions CHECK (\n",
    "        transaction_date >= '2020-01-01' AND \n",
    "        transaction_date <= CURRENT_DATE() + INTERVAL 1 DAY\n",
    "    ),\n",
    "    \n",
    "    -- Segregation of duties\n",
    "    CONSTRAINT segregation_of_duties CHECK (\n",
    "        CASE WHEN ABS(amount) > 10000 \n",
    "             THEN approved_by IS NOT NULL AND approved_by != created_by\n",
    "             ELSE true END\n",
    "    ),\n",
    "    \n",
    "    -- Audit trail requirements\n",
    "    CONSTRAINT audit_trail_required CHECK (audit_trail_id IS NOT NULL)\n",
    ") \n",
    "TBLPROPERTIES (\n",
    "    'sox_control' = 'ITGC_001',\n",
    "    'retention_period' = '2555_days',  -- 7 years minimum\n",
    "    'audit_frequency' = 'quarterly',\n",
    "    'deletion_prohibited' = 'true'\n",
    ");\n",
    "```\n",
    "\n",
    "**3. HIPAA (Health Insurance Portability and Accountability Act):**\n",
    "\n",
    "**Protected Health Information (PHI):**\n",
    "```sql\n",
    "-- HIPAA minimum necessary standard\n",
    "CREATE TABLE patient_records (\n",
    "    patient_id STRING NOT NULL,\n",
    "    medical_record_number STRING NOT NULL,\n",
    "    diagnosis_date DATE NOT NULL,\n",
    "    treatment_code STRING NOT NULL,\n",
    "    provider_id STRING NOT NULL,\n",
    "    \n",
    "    -- HIPAA data quality requirements\n",
    "    CONSTRAINT valid_medical_record CHECK (LENGTH(medical_record_number) >= 8),\n",
    "    CONSTRAINT reasonable_diagnosis_date CHECK (\n",
    "        diagnosis_date >= '1900-01-01' AND \n",
    "        diagnosis_date <= CURRENT_DATE()\n",
    "    ),\n",
    "    CONSTRAINT valid_treatment_code CHECK (treatment_code LIKE 'ICD-%'),\n",
    "    \n",
    "    -- Access control metadata\n",
    "    last_accessed_by STRING,\n",
    "    last_access_timestamp TIMESTAMP,\n",
    "    access_purpose STRING,\n",
    "    \n",
    "    CONSTRAINT valid_access_purpose CHECK (\n",
    "        access_purpose IN ('treatment', 'payment', 'operations', 'research_approved')\n",
    "    )\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    'contains_phi' = 'true',\n",
    "    'hipaa_covered_entity' = 'true',\n",
    "    'minimum_necessary_applied' = 'true',\n",
    "    'breach_notification_required' = 'true',\n",
    "    'retention_period' = '2190_days'  -- 6 years\n",
    ");\n",
    "```\n",
    "\n",
    "**4. PCI DSS (Payment Card Industry Data Security Standard):**\n",
    "\n",
    "**Cardholder Data Protection:**\n",
    "```sql\n",
    "-- PCI DSS Requirement 3: Protect stored cardholder data\n",
    "CREATE TABLE payment_transactions (\n",
    "    transaction_id STRING NOT NULL,\n",
    "    merchant_id STRING NOT NULL,\n",
    "    transaction_amount DECIMAL(10,2) NOT NULL,\n",
    "    currency_code STRING NOT NULL,\n",
    "    transaction_timestamp TIMESTAMP NOT NULL,\n",
    "    \n",
    "    -- PCI DSS data protection constraints  \n",
    "    card_token STRING NOT NULL,  -- Tokenized, not actual card number\n",
    "    last_four_digits STRING,\n",
    "    \n",
    "    -- No storage of prohibited data (enforced by constraints)\n",
    "    CONSTRAINT no_full_pan CHECK (card_token NOT LIKE '%[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]%'),\n",
    "    CONSTRAINT valid_last_four CHECK (last_four_digits IS NULL OR \n",
    "        (LENGTH(last_four_digits) = 4 AND last_four_digits REGEXP '^[0-9]{4}$')),\n",
    "    \n",
    "    -- Transaction validation\n",
    "    CONSTRAINT positive_amount CHECK (transaction_amount > 0),\n",
    "    CONSTRAINT valid_currency CHECK (LENGTH(currency_code) = 3),\n",
    "    CONSTRAINT recent_transaction CHECK (\n",
    "        transaction_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 30 DAYS\n",
    "    )\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    'pci_dss_scope' = 'true',\n",
    "    'cardholder_data_present' = 'tokenized_only',\n",
    "    'encryption_required' = 'aes_256',\n",
    "    'access_logging_required' = 'true',\n",
    "    'retention_period' = '365_days'\n",
    ");\n",
    "```\n",
    "\n",
    "**5. Cross-Regulatory Constraint Patterns:**\n",
    "\n",
    "**Universal Compliance Patterns:**\n",
    "```sql\n",
    "-- Pattern for audit trail tables\n",
    "CREATE TABLE audit_log_template (\n",
    "    event_id STRING NOT NULL,\n",
    "    table_name STRING NOT NULL,\n",
    "    operation_type STRING NOT NULL,\n",
    "    user_id STRING NOT NULL,\n",
    "    event_timestamp TIMESTAMP NOT NULL,\n",
    "    before_values STRING,  -- JSON of old values\n",
    "    after_values STRING,   -- JSON of new values\n",
    "    \n",
    "    -- Universal audit constraints\n",
    "    CONSTRAINT valid_operation CHECK (\n",
    "        operation_type IN ('INSERT', 'UPDATE', 'DELETE', 'SELECT')\n",
    "    ),\n",
    "    CONSTRAINT recent_event CHECK (\n",
    "        event_timestamp <= CURRENT_TIMESTAMP() AND\n",
    "        event_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 10 YEARS\n",
    "    ),\n",
    "    CONSTRAINT audit_completeness CHECK (\n",
    "        CASE operation_type\n",
    "            WHEN 'INSERT' THEN after_values IS NOT NULL\n",
    "            WHEN 'UPDATE' THEN before_values IS NOT NULL AND after_values IS NOT NULL  \n",
    "            WHEN 'DELETE' THEN before_values IS NOT NULL\n",
    "            ELSE true\n",
    "        END\n",
    "    )\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    'audit_table' = 'true',\n",
    "    'deletion_prohibited' = 'true',\n",
    "    'retention_period' = '3650_days',  -- 10 years\n",
    "    'compliance_frameworks' = 'SOX,GDPR,HIPAA,PCI_DSS'\n",
    ");\n",
    "```\n",
    "\n",
    "**Constraint-Based Compliance Benefits:**\n",
    "\n",
    "1. **Automated Enforcement:** Constraints automatically prevent non-compliant data\n",
    "2. **Audit Evidence:** Constraint violations provide audit trail of compliance attempts  \n",
    "3. **Risk Mitigation:** Technical controls reduce human error in compliance\n",
    "4. **Documentation:** Constraints serve as machine-readable compliance documentation\n",
    "5. **Continuous Monitoring:** Constraint violations can trigger compliance alerts\n",
    "6. **Data Quality:** Ensures compliance data meets regulatory quality standards\n",
    "\n",
    "**Implementation Best Practices:**\n",
    "\n",
    "```sql\n",
    "-- Compliance metadata template\n",
    "ALTER TABLE compliance_critical_table SET TBLPROPERTIES (\n",
    "    'compliance_frameworks' = 'GDPR,SOX,HIPAA',\n",
    "    'compliance_owner' = 'chief_compliance_officer',\n",
    "    'last_compliance_audit' = '2023-09-15',\n",
    "    'next_compliance_audit' = '2024-03-15',\n",
    "    'compliance_status' = 'compliant',\n",
    "    'automated_compliance_checks' = 'enabled',\n",
    "    'manual_review_required' = 'quarterly'\n",
    ");\n",
    "```\n",
    "\n",
    "This comprehensive approach ensures that Unity Catalog constraints not only enforce data quality but also provide the technical foundation for regulatory compliance across multiple frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This solution guide provides comprehensive answers to all lab questions, covering:\n",
    "\n",
    "1. **Unity Catalog Fundamentals**: Managed vs external tables, storage, and governance\n",
    "2. **External Locations**: Security, compliance, and architecture benefits  \n",
    "3. **View Types**: Temporary, global temporary, and stored views for different use cases\n",
    "4. **CTAS Operations**: Performance, complexity, and design considerations\n",
    "5. **Delta Constraints**: Enforced vs metadata-only constraints and their purposes\n",
    "6. **Advanced Scenarios**: Complex business rules and multi-constraint handling\n",
    "7. **Data Governance**: Metadata management and compliance support\n",
    "\n",
    "Each solution includes practical examples, best practices, and real-world implementation guidance to help students master Unity Catalog and Delta Lake constraint concepts for production environments."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1-Solution-UnityCatalog_and_TableManagement",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
